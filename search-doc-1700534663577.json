{"searchDocs":[{"title":"Bayesian thinking","type":0,"sectionRef":"#","url":"/blog/bayesian_thinking","content":"","keywords":"","version":null},{"title":"Artificial Intelligence","type":0,"sectionRef":"#","url":"/blog/ai","content":"","keywords":"","version":null},{"title":"General​","type":1,"pageTitle":"Artificial Intelligence","url":"/blog/ai#general","content":"General methods are almost always better than imposing human knowledge on the system (e.g. Alpha Go Zero, Image Processing with edges vs deep learning). The only case where human knowledge might help a bit is when you have a product that is not working without a lot of data and that data is only obtainable during operation, for example self driving cars. Then, it might be helpful to develop a lower capability system with the help of human knowledge to have a sellable system and get the data to train the system from scratch without human knowledge (e.g. Tesla FSD) ","version":null,"tagName":"h2"},{"title":"classes","type":0,"sectionRef":"#","url":"/blog/classes","content":"","keywords":"","version":null},{"title":"30 (masterarbeit)​","type":1,"pageTitle":"classes","url":"/blog/classes#30-masterarbeit","content":"120 ","version":null,"tagName":"h2"},{"title":"Coding","type":0,"sectionRef":"#","url":"/blog/coding","content":"","keywords":"","version":null},{"title":"Gitignore​","type":1,"pageTitle":"Coding","url":"/blog/coding#gitignore","content":"Just select a gitignore template when creating a repository on github. Overview can be found here. ","version":null,"tagName":"h2"},{"title":"Python random seed​","type":1,"pageTitle":"Coding","url":"/blog/coding#python-random-seed","content":"Need to set the seed in the file of the execution of the function. If the function is imported from another file, the seed will not be set for the imported function. Same for PyTorch. ","version":null,"tagName":"h2"},{"title":"Vim tips​","type":1,"pageTitle":"Coding","url":"/blog/coding#vim-tips","content":"gf to open file under cursor (markdown internal links)gx to open file under cursor with default program (images, urls) ","version":null,"tagName":"h2"},{"title":"Local server​","type":1,"pageTitle":"Coding","url":"/blog/coding#local-server","content":"If you get slow load times on every other request only in chrome, use 127.0.0.1 instead of localhost. I think it has something to do with chrome trying to resolve localhost to ipv6 first. ","version":null,"tagName":"h2"},{"title":"Cool python libraries​","type":1,"pageTitle":"Coding","url":"/blog/coding#cool-python-libraries","content":"icecream for nicer printing/logging ","version":null,"tagName":"h2"},{"title":"Python flask sqlite​","type":1,"pageTitle":"Coding","url":"/blog/coding#python-flask-sqlite","content":"When accessing database, the fetchall() function returns a list of sql row objects. When accessing a specific column from one row, in python you need to use bracket notation [string]. In the jinja template you can use the dot notation .string (without quotation marks, like accessing an attribute of an object) or the bracket notation. ","version":null,"tagName":"h2"},{"title":"Daily ToDos","type":0,"sectionRef":"#","url":"/blog/daily","content":"program autotuner for hyperparameter optimization get basic blocks for good project structure going","keywords":"","version":null},{"title":"Data Preparation and Feature Engineering","type":0,"sectionRef":"#","url":"/blog/data_preparation","content":"","keywords":"","version":null},{"title":"When to transform​","type":1,"pageTitle":"Data Preparation and Feature Engineering","url":"/blog/data_preparation#when-to-transform","content":"","version":null,"tagName":"h2"},{"title":"Prior to training​","type":1,"pageTitle":"Data Preparation and Feature Engineering","url":"/blog/data_preparation#prior-to-training","content":"Pros​ computation only performed once Cons​ Transformations need to be reproduced at prediction time. New data can be unpredictable.need to rerun dataset generation when changing transformations, which may lead to slow iterations. Not an issue with a small dataset. ","version":null,"tagName":"h3"},{"title":"Within the model​","type":1,"pageTitle":"Data Preparation and Feature Engineering","url":"/blog/data_preparation#within-the-model","content":"Pros​ can always use the same data, as happen in the model.when changing transformations the same data is still used, which leads to fast iterations. Cons​ transformations can increase latency, this is the case with transformations at prediction time as well. ","version":null,"tagName":"h3"},{"title":"Visualizations​","type":1,"pageTitle":"Data Preparation and Feature Engineering","url":"/blog/data_preparation#visualizations","content":"Always look at graphs or other visualizations of your dataset, before and after transformations to detect errors or irregularities. ","version":null,"tagName":"h2"},{"title":"Normalization​","type":1,"pageTitle":"Data Preparation and Feature Engineering","url":"/blog/data_preparation#normalization","content":"When having features with highly different ranges of numeric values it is recommended to perform normalization. Gradient decent can have issues and slowly converge otherwise. ","version":null,"tagName":"h2"},{"title":"Training Guide","type":0,"sectionRef":"#","url":"/blog/deep_learning","content":"Expand on this.","keywords":"","version":null},{"title":"Docker","type":0,"sectionRef":"#","url":"/blog/docker","content":"I wanted to just have a raw ubuntu install to test my dotfiles. Create Dockerfile FROM ubuntu:latest Build image docker build -t ubuntu . -t creates a tag for this image, to reference it later. Run image docker run --name ubuntu -td ubuntu --name gives the container a name, so you can reference it later. -t allocates a pseudo-TTY, so when all processes defined in Dockerfile are finished, the container will not exit. -d keeps the container running in the background. Attach to container docker exec -i -t ubuntu /bin/bash -i interactive mode -t allocate a pseudo-TTY runs bash in the container and attaches to it. Uses name specified in --name.","keywords":"","version":null},{"title":"Electric vehicles","type":0,"sectionRef":"#","url":"/blog/electric_vehicles","content":"Ideally we would all be using public transport, bicyles and our legs. But humans want for various reasons personal vehicles. Currently we mainly use internal combustion engines (ICE) cars. Due to their emission of co2 and resulting human made climate change we need other solutions in the long term. Electric vehicles are the prime candidate for that position. There are other possibilities like hydrogen fuel cell or biofuel engines. But these &quot;solutions&quot; might only be feasible in the future. But we need a solution right now and with battery electric vehicles (BEVs) we have everthing we need. The only thing BEVs lack behind other options is the range and the charging speed. But is not a concern for most people in everyday life because the can charge at home over night and almost never need to drive the maximum range in their daily life. The other concern many people have is that BEVs are actually not more &quot;green&quot; than ICEs due to the high energy use when producing the battery and that buying a tesla is not environmentally friendly. There is a more difficult and an easy argument against this.","keywords":"","version":null},{"title":"CS50","type":0,"sectionRef":"#","url":"/blog/cs50","content":"","keywords":"","version":null},{"title":"Lecture 0​","type":1,"pageTitle":"CS50","url":"/blog/cs50#lecture-0","content":"","version":null,"tagName":"h2"},{"title":"Lecture 1​","type":1,"pageTitle":"CS50","url":"/blog/cs50#lecture-1","content":"","version":null,"tagName":"h2"},{"title":"Compiling​","type":1,"pageTitle":"CS50","url":"/blog/cs50#compiling","content":"make &lt;program_name&gt;  With file ending. Make can be used to compile most files. Then one can execute them without file ending. ./&lt;program_name&gt;  ","version":null,"tagName":"h3"},{"title":"Basic C syntax​","type":1,"pageTitle":"CS50","url":"/blog/cs50#basic-c-syntax","content":"No need to go over this. ","version":null,"tagName":"h3"},{"title":"Lecture 2​","type":1,"pageTitle":"CS50","url":"/blog/cs50#lecture-2","content":"","version":null,"tagName":"h2"},{"title":"Some more compiling​","type":1,"pageTitle":"CS50","url":"/blog/cs50#some-more-compiling","content":"Make is essentially calling the language specific compilers. For C clang is called. With clang includes need to be manually added as an argument. Make does this automatically. Compiling is generally done in multiple steps: Preprocessing: adding in includes and macrosremoving comments Compiling converts code to assembly Assembling converts assembly to binary, which is machine code and can be run on a CPU. Linking puts compiled includes in the binary code. No need to compile includes multiple times. ","version":null,"tagName":"h3"},{"title":"Debugging​","type":1,"pageTitle":"CS50","url":"/blog/cs50#debugging","content":"Bugs are errors in a program, so that it performs differently than expected. Finding and fixing these errors is called Debugging. ","version":null,"tagName":"h3"},{"title":"Lecture 3​","type":1,"pageTitle":"CS50","url":"/blog/cs50#lecture-3","content":"","version":null,"tagName":"h2"},{"title":"Search​","type":1,"pageTitle":"CS50","url":"/blog/cs50#search","content":"Arrays are just lists of entries. Computers can only look at one entry at a time, so search algorithms are needed to look up specific entries. ","version":null,"tagName":"h3"},{"title":"Big O​","type":1,"pageTitle":"CS50","url":"/blog/cs50#big-o","content":"Most search algorithms try to achieve the same thing. The main difference is the running time. This is not exactly in seconds but as the complexity of the algorithm. To do that one uses the big O notation, which describes how much time the algorithm takes approximately dependent on the size of the problem. The most common running times are: \\(O(n^2)\\)\\(O(n \\log n)\\)\\(O(n)\\)\\(O(\\log n)\\)\\(O(1)\\) The \\(O\\) describes the upper bound of time steps an algorithm takes. The lower bound is described by \\(\\Omega\\), and if the two are the same one uses \\(\\Theta\\). ","version":null,"tagName":"h3"},{"title":"Different search algorithms​","type":1,"pageTitle":"CS50","url":"/blog/cs50#different-search-algorithms","content":"Here. ","version":null,"tagName":"h3"},{"title":"Different sorting algorithms​","type":1,"pageTitle":"CS50","url":"/blog/cs50#different-sorting-algorithms","content":"Some Sort Algorithms. ","version":null,"tagName":"h3"},{"title":"Recursion​","type":1,"pageTitle":"CS50","url":"/blog/cs50#recursion","content":"Recursion can be helpful to express logic, for example binary search. One needs to be careful when defining the breaking condition, so not too much memory is used by going too deep. ","version":null,"tagName":"h3"},{"title":"Lecture 4​","type":1,"pageTitle":"CS50","url":"/blog/cs50#lecture-4","content":"Pointers are variables which store memory addresses where the values of other variables might be stored. It's important to know the difference, so not to copy the address and think one copied the value of the variable. The Syntax for arrays just uses the address of the first element and adds the indices of the successive elements to that address. Same is happening with strings. Strings are just one pointer to the first character. The computer looks at the successive addresses and stops at the element \\0. It's important to know that when accessing uninitialized memory one can see values that have been saved by previous programs at that address. This can be dangerous, if there are passwords saved for example. One can check memory errors with valgrind on the command line. All this is important if one wants to make the program as efficient as possible and debug deep down. But for high level languages like python this is not as important as python mostly handles this for you, with less efficiency. ","version":null,"tagName":"h2"},{"title":"Lecture 5​","type":1,"pageTitle":"CS50","url":"/blog/cs50#lecture-5","content":"","version":null,"tagName":"h2"},{"title":"Linked lists​","type":1,"pageTitle":"CS50","url":"/blog/cs50#linked-lists","content":"Linked lists are list where the elements are not stored behind each other in memory but at separate places. After the first value one needs to store a pointer to the next value, and so on. If one wants to add a element to a normal array and the memory slot after the originally last element is already full, we have an issue. We can either copy the array to a new location in memory with enough space, which requires some runtime, or we use a linked list where adding a new element is trivial, as the element after the last element is always reserved for a pointer to a potential new element. So if we have a constant length list, use a normal array, as the linked list would require more memory. If we might change the length of the list, use a linked list, as the overhead is less than the potential cost of copying a normal array. ","version":null,"tagName":"h3"},{"title":"Trees​","type":1,"pageTitle":"CS50","url":"/blog/cs50#trees","content":"Trees are just defined by nodes. A node is a data structure which has one value and can have multiple pointers to child nodes. ","version":null,"tagName":"h3"},{"title":"Other data structures​","type":1,"pageTitle":"CS50","url":"/blog/cs50#other-data-structures","content":"There are several other data structures like queues (first-in-first-out), stacks (last-in-first-out) and dictionaries. ","version":null,"tagName":"h3"},{"title":"Lecture 6​","type":1,"pageTitle":"CS50","url":"/blog/cs50#lecture-6","content":"","version":null,"tagName":"h2"},{"title":"Learning a new programming language​","type":1,"pageTitle":"CS50","url":"/blog/cs50#learning-a-new-programming-language","content":"Most programming languages are pretty similar. All of them have conditions, operators, data structures and other things. Differences are often just syntax or bigger things like how they handle scopes of variables and types. All in all, if you have mastered one language it is pretty easy to learn another language up to a decent level. ","version":null,"tagName":"h3"},{"title":"Lecture 7​","type":1,"pageTitle":"CS50","url":"/blog/cs50#lecture-7","content":"","version":null,"tagName":"h2"},{"title":"Data processing​","type":1,"pageTitle":"CS50","url":"/blog/cs50#data-processing","content":"When downloading datasets or even collecting them yourself, most of them are not cleaned. Which means, there might be typos, different names for the same thing, columns which should be multiple columns and much more ugliness. Python is well equipped to clean data, especially with the help of regular expressions. However for quick fixes or searches a database language like sqlite is probably easier. To combine both, one can execute sql commands from within python with the sqlite library. When working with databases the most important thing is to escape user input to avoid injection attacks. When working with multiple servers and multiple users one should lock data that is currently changed by one server. Otherwise a second server might change the same data at the same time and one change gets lost or even worse unintended stuff happens. ","version":null,"tagName":"h3"},{"title":"Lecture 8​","type":1,"pageTitle":"CS50","url":"/blog/cs50#lecture-8","content":"","version":null,"tagName":"h2"},{"title":"The internet​","type":1,"pageTitle":"CS50","url":"/blog/cs50#the-internet","content":"IP​ The internet is basically just a big web of all the routers and in extension the computers/devices and servers of a lot of people in the world. One can send information to any other point in that web. To achieve that, one needs the internet protocol (IP) to tell the routers where to send the information. TPC/UDP​ TPC is another protocol that helps with sending information to different programs of one IP address. It also allows sending large chunks of data in multiple parts. If the user has a bad connection certain parts can be sent again instead of all the parts. UDP is a protocol that allows sending large amounts of data, but it doesn't grantee delivery. This is useful for calls or other real time applications as one doesn't want to wait for new data, just to resend earlier data to get the perfect result. DNS​ When you type in a address in your web browser the computer and then your router somehow needs to know what IP address corresponds to the web address. This is done with DNS servers, which have huge lists which save these correspondences. So your router always first contacts a DNS server and gets a IP address back, which then can be used to contact the correct server to get the information one wants. ","version":null,"tagName":"h3"},{"title":"Clientside​","type":1,"pageTitle":"CS50","url":"/blog/cs50#clientside","content":"HTTP​ Browsers use Hypertext Transfer Protocol (HTTP) to interface with TPC/IP packets. HTTPS ensures the packets that arrive at the browser are encrypted. URL​ A web address like https://www.google.com is also called a URL. GET/POST​ GET and POST requests can be used by browsers to request content from servers. You can use curl on the command line to check the headers of the responses of servers to GET requests. curl -I -X GET https://www.harvard.edu/  The status codes one gets back can then be interpreted and used to modify the request to get the correct response. HTML​ Hypertext Markup Language is used to tell the browser what and how to display information. It is however not a programming language. CSS​ To style HTML one can use Cascading Style Sheets (CSS) which isn't a programming language either. JavaScript​ To change elements and styling one can use JavaScript, which is a programming language. It will be executed on the device of the user. ","version":null,"tagName":"h3"},{"title":"Lecture 9​","type":1,"pageTitle":"CS50","url":"/blog/cs50#lecture-9","content":"","version":null,"tagName":"h2"},{"title":"Web server programming​","type":1,"pageTitle":"CS50","url":"/blog/cs50#web-server-programming","content":"A framework like flask or django can be used to program a server with python to send responses to users. So when the user types in a certain URL or clicks on a link, the server sends data in terms of a HTML page, CSS and JavaScript back. This data can be dynamically generated with the full power of python. The python code then communicates on the server with a database, sometimes on another server. This enables accounts and other things where the website needs to remember stuff about the user. Often times, for example for autocomplete it is helpful to use a mix of JavaScript and serverside code to accelerate the results, as responses from the server take some time compared to calculations on device. ","version":null,"tagName":"h3"},{"title":"Fake news","type":0,"sectionRef":"#","url":"/blog/fakenews","content":"","keywords":"","version":null},{"title":"Google bias​","type":1,"pageTitle":"Fake news","url":"/blog/fakenews#google-bias","content":"","version":null,"tagName":"h2"},{"title":"The Enduring Anti-Black Racism of Google Search​","type":1,"pageTitle":"Fake news","url":"/blog/fakenews#the-enduring-anti-black-racism-of-google-search","content":"link: https://onezero.medium.com/the-enduring-anti-black-racism-of-google-search-d024924bff77 Bad article​ A search engines job should be to get users the information they want. It feels like the baseline for zero bias is what the internet offers. So when the whole internet is nine images of an apple and one image of a banana, it would be good to expect an apple more often when searching for &quot;fruit&quot;. So when there are the tags for &quot;black girls&quot; are overwhelmingly found on porn sites it should be to no surprise that google shows those when searching for &quot;black girls&quot;. It feels like, if google would not intervene in the &quot;societal&quot; distribution of the search results, we would have more racist search results, as one can see at the exact example in the article. So to blame google instead of the culture of the people is wrong. So google actually does bias the results, however one could argue that that's a good thing. The author shouldn't blame google for the few times reality was shining through, but thank google for adjusting some bad baselines in society. It might be helpful to get some diversification in the workplace to help these things, however those need not necessarily be engineers, as the manual adjustments shouldn't have anything to do with engineering, rather with social studies or ethics. The whole thing is hard to evaluate since we don't exactly know how google selects the search results, however the alternatives are hard to imagine. Is the implication of the article that google engineers went ahead and weighted porn websites higher when searching for &quot;black girls&quot; instead of &quot;white girls&quot;? What would be the motive behind that? Some weird quotes​ Pornography is a specific type of representation that denotes male power, female powerlessness, and sexual violence. This feels wrong. Porn on the internet is an expansion of neoliberal capitalist interests. The web itself has opened up new centers of profit and pushed the boundaries of consumption. Never before have there been so many points for the transmission and consumption of these representations of Black women’s bodies, largely trafficked outside the control and benefit of Black women and girls themselves. Why is an expansion of capitalist interests bad?Isn't that good for a lot of people?What does neoliberalism have to do with it? The assumption that the consumption is &quot;largely&quot; outside the benefit of black woman needs to be justified. black woman that do porn do benefit? If they are exploited there is another question. (more fame, money, like music labels)why only for black woman? And what about men in porn? (earn way less than woman) ","version":null,"tagName":"h3"},{"title":"Gunn and Lynch Googling (2019)​","type":1,"pageTitle":"Fake news","url":"/blog/fakenews#gunn-and-lynch-googling-2019","content":"Chapter 4, page 41-51 Risks of googling​ anonymity, no accountability of face-to-face information. Not a google issue, internet issue.no way to make sure that information is good, same issue in real life, but internet gives broader view quickly. One needs to check multiple sources, integrate in world view and check for inconsistencies.reductionism reductionism: trust is earned not assumedanti-reductionism: just trust others, assuming they have similar thinking faculties google searches lead to most wanted results, assumed to be right, because many others found it to be righttrust if author is trusted, problematic, but not unique to internet collective of authors (wikis)some are automated (currency exchange) selecting sources​ more reliable information is shared more, higher in ranking, goodsometimes information of influencers does have popularity-because-popular, badthere are often experts on both sides, use institutional markersuse of likes, upvotes, titles (must not necessarily be a good marker)advertising can be misleadingWikipedia can be good as everything needs source from expert, but can be outdated due to lag of checkupsnot all people are able to select &quot;good&quot; sources, most just accept everything google gives them first. Google in Brain​ extend brain with chip, access fast amounts of information at speed of thoughtaccelerates effects/issues above ","version":null,"tagName":"h3"},{"title":"Epistemic Agency​","type":1,"pageTitle":"Fake news","url":"/blog/fakenews#epistemic-agency","content":"","version":null,"tagName":"h2"},{"title":"Tugend​","type":1,"pageTitle":"Fake news","url":"/blog/fakenews#tugend","content":"Verantwortung Anonymity ","version":null,"tagName":"h3"},{"title":"On trusting Wikipedia​","type":1,"pageTitle":"Fake news","url":"/blog/fakenews#on-trusting-wikipedia","content":"generally trustednot always correct ","version":null,"tagName":"h2"},{"title":"Wikipedia and the epistemology of testimony (by deborah perron tollefsen)​","type":1,"pageTitle":"Fake news","url":"/blog/fakenews#wikipedia-and-the-epistemology-of-testimony-by-deborah-perron-tollefsen","content":"","version":null,"tagName":"h2"},{"title":"Introduction​","type":1,"pageTitle":"Fake news","url":"/blog/fakenews#introduction","content":"studies mainly focus on individual testimonygroup testimony can't always be understood as just a summation of individual testimonythe group itself testifiesexample Wikipedia ","version":null,"tagName":"h3"},{"title":"Questions​","type":1,"pageTitle":"Fake news","url":"/blog/fakenews#questions","content":"Is Wikipedia a source of testimony?What is the nature of that source? the individuals that make entriesa subset of individualsthe entity Wikipedia itself How can we asses the trustworthiness of Wikipedia as such an unusual epistemic source? ","version":null,"tagName":"h3"},{"title":"Are the statements on Wikipedia testimony?​","type":1,"pageTitle":"Fake news","url":"/blog/fakenews#are-the-statements-on-wikipedia-testimony","content":"define testimony​ conservative (Coady 1992) speakers intention to present evidence on a specific matter in the interest of the audience liberal (E. Fricker 1995, Sosa 1991) &quot;tellings in general&quot; with no restriction on the domain Jennifer Lackey (2006) &quot;S testifies that p by making an act of communication a if and only if (in part) in virtue of a’s communicable content, (1) S reasonably intends to convey the information that p, or (2) a is reasonably taken as conveying the information that p.&quot;so it is a testimony if the speaker intends to convey information or if the audience takes it as such Wikipedia as testimony​ All would obviously include Wikipedia as testimony. Assumption: People are trolling, writing false information for fun. Some definitions of testimony might be broken. Lackey's definition would still include Wikipedia as testimony, as people who read Wikipedia still assume it to be testimony. Wray: not all entries are testimony, some are jokes, so nothing is testimony. Doesn't mean nothing is testimony. Testimony is not only what one believes, otherwise there would be no false testimony. Moran(2006), Assurance view: Testimony comes with assurance that statement is true. Testifiers have responsibility to be truthful. They are aware that they might be questioned and need to explain themselves if the statement is false. The same is true on Wikipedia. People can change information, but they know that they can then be called to question by other people that can discuss these changes and change them again. Even if a troll is sometimes hard to track down and question, the information still is taken to come with assurances. So none of the definitions of testimony would exclude Wikipedia as testimony. ","version":null,"tagName":"h3"},{"title":"Group testimony​","type":1,"pageTitle":"Fake news","url":"/blog/fakenews#group-testimony","content":"New Question: Is the source the person that writes the entry or the entity Wikipedia? When group decides something, it doesn't necessarily follow that all or most of the group, would testify the similarly. Example: NAS needed to make statement on long term genetic hazards of radiation exposure. It was a difficult decision, but needed to be made to protect the public from other, more harmful misinformation. Some scientists even refused to sign it, because they thought it was indeterminable. In the end they all signed. For a group G, speaker S, and utterance x, G utters x if and only if: There exists a group (G), this group has an illocutionary intention, and x conveys that illocutionary intention.S believes that he or she knows the illocutionary intention of G and that x conveys this illocutionary intention.G does not object to S uttering x on its behalf and if G intends for any specific individual(s) to utter x, it intends for S to utter x. S believes that he or she knows this.2 and 3 are the reasons S utters x. Need to add 5th condition. S utters G in the proper social and normative context. This is important, as the NAS group would probably not have signed the statements, if it wasn't necessary to keep public trust and safety. So group testimony (group speech act with conveyed information): Group G testifies that p by making an act of communication a if and only if: (in part) in virtue of a’s communicable content G reasonably intends to convey the information that p.The information that p is conveyed by either (i) a spokesperson S or (ii) a written document.If (i), G does not object to S’s uttering p on its behalf and if G intends for any specific individual(s) to utter p, it intends for S to utter p and S believes that he or she knows this.If (i), S utters p for the reasons in 3.If (ii), G does not object to the way in which p is conveyed in writing.G conveys the information that p in the right social and normative context.In conveying the information that p in the right social and normative context, G is taken to have given its assurance that p is true. ","version":null,"tagName":"h3"},{"title":"Wikipedia entries as group testimony​","type":1,"pageTitle":"Fake news","url":"/blog/fakenews#wikipedia-entries-as-group-testimony","content":"Traits shared by groups (research teams, governments or corporations) share certain goals clear goals on Wikipedia: natural, balanced, verifiable knowledge to all for freecontributors have largely those goals, would be hard to explain otherwise are aware that they share these goals &quot;Wikipedia community&quot;, &quot;Wikipedians&quot; are names used, Wikipedia conferences existthere are pages on Wikipedia that explain itself, so its self reflective group decision making process with specific rulesgroup members have special rights and obligations Articles are testimony of Wikipedia once they have been discussed at length and have been approved by the community, they become featured or good articles. Until then, they are either individual or group testimony. The trustworthiness of Wikipedia needs to be monitored in those early stages, while &quot;steadying ones mind&quot;, almost like a child. ","version":null,"tagName":"h3"},{"title":"Trustworthiness of Wikipedia​","type":1,"pageTitle":"Fake news","url":"/blog/fakenews#trustworthiness-of-wikipedia","content":"Anti-reductionism: Trust others, assuming they have similar thinking faculties. (normal conversation) Reductionism: Trust, if there are positive reasons, that the other person is sincere/reliable. Anti-reductionism​ Normal conversation with one person is on topics with not expertise, so anti-reductionism is fine. Generally groups have some kind of specific expertise (governmental, scientific, legal). With Wikipedia its different, because it speaks on a wide range of interests (more like a person on the street). However the standard trust assumption of anti-reductionism may fail with Wikipedia, if it's treated as a child/unstable. Reductionism​ Scrutinize the speaker/Wikipedia​ Sum of individuals: check if some or all of the contributors are reliableoften short track record of contributors, hard to evaluatemature articles could be closer to the truth than the individual entries of the contributors through the process of discussion and approvalmight tell us nothing about the trustworthiness of Wikipedia Systematic cues: Programs can figure out anomalies (quick changes without discussion after long stable period, information that doesn't fit into the style of the article)quick correction of spelling/grammatical errors might hide red flags for the content of the entry from the reader; one can still check the history (most probably wont)trust the system not the individuals Scrutinize the content​ Verify with own background knowledge. Integrate in world view and check for inconsistencies. A UFO landed on the school roof (unlikely because of prior believe) Trust the process and the reports, not the individuals. There are incentives for groups to tell the truth(scientific groups, some corporations) If group testimony is wildly at odds with your own knowledge, one has no reason to trust it. Wikipedia: incentives are in the structure of the systementries will be checked against background knowledgeby challenging Wikipedia, its reliability increases through new policies and procedures ","version":null,"tagName":"h3"},{"title":"Conclusion​","type":1,"pageTitle":"Fake news","url":"/blog/fakenews#conclusion","content":"Wikipedia involves a mix of individual, group and Wikipedia testimonyCan't trust Wikipedia by default, yet (still a child)Will get better once it matures, and doesn't need to be constantly monitored ","version":null,"tagName":"h3"},{"title":"Discussion Questions​","type":1,"pageTitle":"Fake news","url":"/blog/fakenews#discussion-questions","content":"","version":null,"tagName":"h3"},{"title":"Fake News and Partisan Epistemology​","type":1,"pageTitle":"Fake news","url":"/blog/fakenews#fake-news-and-partisan-epistemology","content":"","version":null,"tagName":"h2"},{"title":"Context Collapse​","type":1,"pageTitle":"Fake news","url":"/blog/fakenews#context-collapse","content":"","version":null,"tagName":"h2"},{"title":"Hopeful Trust​","type":1,"pageTitle":"Fake news","url":"/blog/fakenews#hopeful-trust","content":"Pendulum swung too far: Tweets with misinformation are taken as truth because of labels of person (trans, black); Trust gets abused by speaker. It is assumed people trust the person just because of the label. Examples disproportionally damage trust in truthful speakers. trans person claiming periods https://twitter.com/poisonaivy69/status/1507362480158355508jakob blake misinfo vulnerability invites trust, but only sometimes. On social media, one needs to take the average to see effect trump voters meet trans people in real life ","version":null,"tagName":"h2"},{"title":"Habits","type":0,"sectionRef":"#","url":"/blog/habits","content":"","keywords":"","version":null},{"title":"Don't multitask​","type":1,"pageTitle":"Habits","url":"/blog/habits#dont-multitask","content":"It just doesn't work, you think it works, but it doesn't. You're just switching between tasks, and you're not doing any of them well. Or you are doing one with 80% of your brain and the other 20%, so the one with 20% isn't even enjoyed, so why not do it with 100% of your brain in your free time. ","version":null,"tagName":"h2"},{"title":"Social media/ entertainment​","type":1,"pageTitle":"Habits","url":"/blog/habits#social-media-entertainment","content":"Only watch them while eating or in free time. Then you can watch the highlights of the day, and not needing to search for cool stuff while you should be working or doing other things. ","version":null,"tagName":"h2"},{"title":"Sleep​","type":1,"pageTitle":"Habits","url":"/blog/habits#sleep","content":"Keep sleep schedule, wake up early, try 8h. ","version":null,"tagName":"h2"},{"title":"Exercise​","type":1,"pageTitle":"Habits","url":"/blog/habits#exercise","content":"Mix running and at home exercise, depending on weather and state of mind. Don't miss two days in a row. Its easy to lose the habit then. ","version":null,"tagName":"h2"},{"title":"Eat healthy​","type":1,"pageTitle":"Habits","url":"/blog/habits#eat-healthy","content":"Just count your calories, and eat filling foods. Mix it up, change some vegetables, proteins and spices in the recipes, mix up rice with noodles or lentils. ","version":null,"tagName":"h2"},{"title":"Work​","type":1,"pageTitle":"Habits","url":"/blog/habits#work","content":"Eliminate distractions. Block websites like YouTube, Twitch, Twitter, etc. Work for selected periods of time, but focused. ","version":null,"tagName":"h2"},{"title":"Do your bed​","type":1,"pageTitle":"Habits","url":"/blog/habits#do-your-bed","content":"Yeah, sounds like the meme daddy Peterson tells you, but it helps, its a small task that's easy to accomplish, and it makes you feel good. It's a good habit to start with. ","version":null,"tagName":"h2"},{"title":"Shower​","type":1,"pageTitle":"Habits","url":"/blog/habits#shower","content":"Just shower early in morning, makes you feel fresh and ready for the day. And wear clothes that you would wear in public or work. Makes you feel ready. ","version":null,"tagName":"h2"},{"title":"Walks​","type":1,"pageTitle":"Habits","url":"/blog/habits#walks","content":"Take a walk without any distractions. No phone, just enjoy the nature. It's good for your mind and body. It may sound stupid, but it will make you feel better. ","version":null,"tagName":"h2"},{"title":"ToDo list​","type":1,"pageTitle":"Habits","url":"/blog/habits#todo-list","content":"Don't put too many tasks on there, and make them as small as possible. That way, you can actually achieve them, and don't feel bad because you only managed to complete half of them by the end of the day. ","version":null,"tagName":"h2"},{"title":"Free time​","type":1,"pageTitle":"Habits","url":"/blog/habits#free-time","content":"You need some dedicated time to do whatever you want. If not, it will creep into the time you should be working. Good time to socialize. Meeting friends helps. Default Schedule Time\tTask7:00\tWake up, Shower, Get ready 7:30\tGo for a walk 7:50\tBreakfast 8:15\tSchedule my day 8:30\tWork 12:00\tDo exercise 12:30\tLunch 13:30\tWork 19:00\tDinner 19:30\tDo whatever I want 22:30\tSleep Alternative Schedule Time\tTask7:00\tWake up, Shower, Get ready 7:30\tGo for a walk 7:50\tBreakfast 8:15\tSchedule my day 8:30\tWork 12:00\tDo exercise 12:30\tLunch 13:30\tWork 17:00\tDo whatever I want 22:30\tSleep Rules Only use social media during food slotsSocialize only after 16:00, if work is done.Can take two days off each week, if i feel like it.If I feel healthy and motivated, I can follow the routine every single day, without off days. Food Plan (Weekly): Day\tMealMonday\tTofu, zucchini, bell pepper, soy sauce, ginger stir fry with white rice Tuesday\tLentil soup with a side of whole grain crackers/bread Wednesday\tQuinoa bowl with roasted mushrooms and brokkoli with lemon juice Thursday\tTofu, zucchini, bell pepper, soy sauce, ginger stir fry with white rice Friday\tSpinach and tomato omelet with whole grain toast Saturday\tWrap with hummus, roasted eggplant and arugula Sunday\tTofu, zucchini, bell pepper, soy sauce, ginger stir fry with white rice Every day: Spices (pepper, salt, thyme, rosemary, garlic powder) Shopping List (Wednesday): ","version":null,"tagName":"h2"},{"title":"Fresh:​","type":1,"pageTitle":"Habits","url":"/blog/habits#fresh","content":"","version":null,"tagName":"h2"},{"title":"Vegetables/Fruits:​","type":1,"pageTitle":"Habits","url":"/blog/habits#vegetablesfruits","content":"3x zucchini3x bell pepper3x mushrooms1x eggplanttomatoesbrokkolifresh spinacharugula3x ginger ","version":null,"tagName":"h3"},{"title":"Other:​","type":1,"pageTitle":"Habits","url":"/blog/habits#other","content":"3x tofuhummus4x eggswrapscheese ","version":null,"tagName":"h3"},{"title":"Bulk:​","type":1,"pageTitle":"Habits","url":"/blog/habits#bulk","content":"soy saucequinoalentilswhite ricewhole grain crackers/breadhummuslemon juice (oil)spices (pepper, salt, thyme, rosemary, garlic powder)vegetable broth powder ","version":null,"tagName":"h2"},{"title":"Investing","type":0,"sectionRef":"#","url":"/blog/etf_investing","content":"","keywords":"","version":null},{"title":"Timeframe​","type":1,"pageTitle":"Investing","url":"/blog/etf_investing#timeframe","content":"~15 years ","version":null,"tagName":"h2"},{"title":"ETF​","type":1,"pageTitle":"Investing","url":"/blog/etf_investing#etf","content":"ETFs sind wie Fonds, kleine Anteile von Unternehmen in &quot;Packet&quot;. Kann dadurch über verschiedene Branchen und über die ganze Welt geographisch gestreut werden. Daraus folgt, dass nicht mehr in bestimmte Unternehmen, sondern in den gesamten Markt investiert wird. Der Unterschied von ETFs im Vergleich zu Fonds ist das Management. Fonds werden von Angestellten von Banken gemanaged und aktiv Aktien hinzugefügt oder verkauft. Dies ist mit Personalkosten verbunden. ETFs werden automatisch gemanaged und versuchen so genau wie möglich einem Index zu folgen. Diese Indizes werden auf Basis von bestimmten Regeln aufgestellt. Mcsi world setzt sich beispielsweise aus den top (70%) Unternehmen mit den höchsten Marktkapitalisierung aus bestimmten Ländern zusammen. Die Kostenunterschiede zwischen ETFs und aktiven Fonds beträgt meist ~1%. Diese Differenz muss durch die Experten der Banken, welche diese Fonds managen, zusätzlich zu der Rendite des ETFs erreicht werden, sodass der Fond ein besseres Investment als der ETF ist. Dies wird meist nicht erreicht bzw. ist wieder ein Glücksspiel in sich selbst, da der &quot;richtige&quot; Fond herausgesucht werden muss und oft sind diese nicht wirklich transparent. Zudem ist es so gut wie unmöglich den Markt zu verstehen und falls Experten dies täten, würden sie vermutlich keine Fonds managen sondern selbst traden und nicht mehr arbeiten müssen. Die Annahme, dass der Markt immer weiter steigt, ist warscheinlich korrekt. Menschen wollen schon immer mehr Dinge und ein &quot;besseres&quot; Leben. Die Industrieländer sind vielen Teilen der Welt vorraus. Auch wenn die Industrieländer sich entscheiden sollten nicht mehr so viel zu produzieren (evtl. auf Grund des Klimawandels) wird vermutlich immer noch der Rest der Welt nachziehen und Güter benötigen. Zudem wird dies vermutlich nicht in den nächsten ~30 Jahren passieren, wenn überhaupt. Mcsi world über 15 jahre (seite down → ähnlich) median rendite 8.78%, schlechteste 3.16% pro jahr (abhängig davon wann gekauft/verkauft wird). Das wichtigste ist, dass die varianz mit längeren Investmentperioden sinkt und nach 10-15 Jahren die Chance für positive Rendite über 90% liegt und nach 20 Jahren gar bei 100% (auf der Seite zu Minimum investment horizon und Compute clicken). Natürlich sind dies historische Daten und garantieren nichts für die Zukunft, jedoch sind sie trotzdem gute Anhaltspunkte, da der gesamte Markt sich in Zukunft vermutlich auf lange Sicht ähnlich verhalten wird. ","version":null,"tagName":"h2"},{"title":"Broker​","type":1,"pageTitle":"Investing","url":"/blog/etf_investing#broker","content":"Hohe Sicherheit (haben eigentlich alle hier in Deutschland + deutsche Einlagensicherung bis 100.000€)keine Verwahrungsgebüren (ist bei den meisten auch so)geringe Kosten für einmaligen Kauf (gut wenn pauschal, schlecht wenn %) Es ist schwer Beispiele zu nennen, da die Konditionen der Broker sich andauernd ändern. Generell bieten jedoch die &quot;alten&quot; Banken schlechtere Konditionen. Ein weiterer wichtiger Faktor ist oft, ob die Broker eine gute App und Website anbieten, da viele Banken noch sehr hinterher sind. Am besten kurz immer YouTube Videos angucken, um die Apps in Aktion zu sehen. Man könnte allerdings auch argumentieren, dass es besser ist keine oder keine gute App zu haben, da dies bei vielen Leuten zu Impuls Käufen oder Verkäufen führen kann, da es so einfach ist. ","version":null,"tagName":"h2"},{"title":"Nachhaltigkeit​","type":1,"pageTitle":"Investing","url":"/blog/etf_investing#nachhaltigkeit","content":"ESG: Ziel ist immer noch Performance. Es werden Unternehmen ausgeschlossen die durch bestimmte umweltschädlichen, sozialen oder ihr Regime negativ auffallen, und dadurch auch eventuell schlechtere Performance erreichen (so weit ich weiß wurde aber noch keine klare Korrelation mit schlechterer Performance festgestellt).SRI: strenger als ESG, suchen aktiv Unternehmen nach ethischen Richtlinien herraus, verwenden allerdings auch teilweise das ESG-Rating zur auswahl, nur die Grenze ist strenger. Gute Videos dafür: [1][2] oder in Text Form. Oder einfach Investopedia. ","version":null,"tagName":"h2"},{"title":"70/30​","type":1,"pageTitle":"Investing","url":"/blog/etf_investing#7030","content":"Mit dem MSCI World werden nur die Industrieländer abgedeckt. Um noch breiter zu diversifizieren ist es sinnvoll ca. 30% des Portfolios in beispielsweise den MSCI World Emerging Markets (EM), welcher viele Schwellenländer noch mit abdeckt. Alternativ ist es noch möglich etwas Europa dazuzunehmen, wenn die Übergewichtung der USA im MSCI World nicht gefällt. Hier noch ein paar andere Porfolioarten zum Vergleich. ","version":null,"tagName":"h2"},{"title":"Mögliche ETFs​","type":1,"pageTitle":"Investing","url":"/blog/etf_investing#mögliche-etfs","content":"MSCI World SRI (70%): Amundi Index MSCI World SRI UCITS ETF DR (WKN: A2JSDA ISIN: LU1861134382) MSCI World Emerging Markets SRI (30%): iShares MSCI EM SRI UCITS ETF (WKN: A2AFCZ ISIN: IE00BYVJRP78)Amundi Index MSCI Emerging Markets SRI UCITS DR ETF (C) (WKN: A2JSDD ISIN: LU1861138961) Zum finden ist justETF gut. Einfach einen Index auswählen und nach Kriterien filtern. Hier noch eine Seite für Tips auf welche Dinge bei der Auswahl zu achten ist. ","version":null,"tagName":"h2"},{"title":"Logic","type":0,"sectionRef":"#","url":"/blog/logic","content":"","keywords":"","version":null},{"title":"Some wiki stuff:​","type":1,"pageTitle":"Logic","url":"/blog/logic#some-wiki-stuff","content":"Argument mapLogical form ","version":null,"tagName":"h2"},{"title":"Idea​","type":1,"pageTitle":"Logic","url":"/blog/logic#idea","content":"It would be cool to have a somewhat standarised form of arguments or moral systems. This could be in form of an Argument map in a huge tree and implemented on a website or in a program. So one could create ones own tree of axioms, premisses and conclusions. Those could be shared and argued about. The program could help identifiy contentions between two peoples moral systems so one can instantly focus on the disagreements. The main issue is the uglieness of human input. Even with a some standard blocks like axioms and other logical forms humans still input their claims differently. So one would need some machine learning to interpret and compare arguments. With the advancements of language models like GTP-3 one may be able to achieve some decent results. ","version":null,"tagName":"h2"},{"title":"How to code","type":0,"sectionRef":"#","url":"/blog/how_to_code","content":"","keywords":"","version":null},{"title":"Hello World Example​","type":1,"pageTitle":"How to code","url":"/blog/how_to_code#hello-world-example","content":"int main() { printf(&quot;hello world\\n&quot;); }  Compile with gcc main.c and run with ./a.out. The compilation will give some errors but it will still run. And you can check out the instructions and memory with objdump -D a.out. ","version":null,"tagName":"h2"},{"title":"Program​","type":1,"pageTitle":"How to code","url":"/blog/how_to_code#program","content":".text: Instructionsbss: Static datastack: local variables (control flow)heap: malloc void a() { int variable_on_the_stack; \\\\ return by popping off the stack } void b() { } int main() { a(); // pushes the return location of the function onto the stack b(); }  So in this example, the computer starts by executing the main function. It then enters the a function and pushes the return location of the function onto the stack. The a function does whatever it does, in our example, create a variable on the stack. When the function ends, the variable gets popped off, so it does not exist anymore. Then the return location gets popped off to know where to return to, in our case the main function after a. This is &quot;real&quot; programming. ","version":null,"tagName":"h2"},{"title":"Programming for work​","type":1,"pageTitle":"How to code","url":"/blog/how_to_code#programming-for-work","content":"What does a software &quot;engineer&quot; do? not writing algorithms In reality they are just translating a (shitty) language aka &quot;business requirements&quot; into &quot;code&quot;. There are a lot of frameworks, like ruby on rails, that do a lot of the work for you (for example a website that enables users to leave their email address). So you don't have to code, you just have to learn some weird syntax. Ruby on rails, React (or similar) --&gt; Web app CRUD apps &lt;-- Create, Read, Update, Delete Frontend (View) Database (Model) Backend/Business Logic (Controller) This whole thing might soon be automated by AI. Build a CRUD app contracting firmRecord all the inputs of my developers (translators for business requirements --&gt; code)Train an AI model to translate &quot;business requirements&quot; --&gt; code So writing these kind of apps, is nothing like writing binary search algorithms or other lower level stuff, which is taught in school. These two things are completely separate. Hacking Input --&gt; System --&gt; Output To gain access to the System you need to know: What input achieves my desired outcome? Often times you can give a system an input that it does not expect and thus manage to get access to the system. Figure out how to make the function behave how you want. ","version":null,"tagName":"h2"},{"title":"Pure model​","type":1,"pageTitle":"How to code","url":"/blog/how_to_code#pure-model","content":"Domain --&gt; Function --&gt; Range y = f(x) ","version":null,"tagName":"h2"},{"title":"Impure model​","type":1,"pageTitle":"How to code","url":"/blog/how_to_code#impure-model","content":"Function can output something outside of the range. ","version":null,"tagName":"h2"},{"title":"Example​","type":1,"pageTitle":"How to code","url":"/blog/how_to_code#example","content":"Let's say we want to cancel a flight without paying the cancellation fee. We can think of a few of the inputs we have to that system (airline agent can press a button on pc to cancel flight and waive the fee): We can call the agent and ask themWe have a huge amount of words to choose from for that conversationWe can do it in personWe can send an emailOr we can do something unexpected, or out of bounds of the &quot;usual&quot; input, like finding personal information about the agent and blackmailing them (not recommended) This way we could essentially hack the system. Guide for Software Engineers ","version":null,"tagName":"h2"},{"title":"High Brow Software Engineering​","type":1,"pageTitle":"How to code","url":"/blog/how_to_code#high-brow-software-engineering","content":"Understand a complex systemModify the system to add a new featureTest and ship the new system ","version":null,"tagName":"h2"},{"title":"Machine Learning Engineer​","type":1,"pageTitle":"How to code","url":"/blog/how_to_code#machine-learning-engineer","content":"Download a paperImplement the paperKeep doing this until you are good Funnels Funnels are essentially just a series of filters that can be applied to some group of things to get to the desired outcome. ","version":null,"tagName":"h2"},{"title":"Selling cars​","type":1,"pageTitle":"How to code","url":"/blog/how_to_code#selling-cars","content":"Top of the funnel: Advertise | 10000 peopleMiddle of the funnel: Test drive | 100 peopleBottom of the funnel: Buy | 5 people ","version":null,"tagName":"h2"},{"title":"Getting a partner​","type":1,"pageTitle":"How to code","url":"/blog/how_to_code#getting-a-partner","content":"Send a message | 100 peopleGet a response | 30 peopleGet a date | 5 peopleLays | 2 personPartner | 1 person ","version":null,"tagName":"h2"},{"title":"Getting money​","type":1,"pageTitle":"How to code","url":"/blog/how_to_code#getting-money","content":"Capitalism. Buyers and Sellers. Both need to consent. So we need to convince others to give us money. How to get 1.000.000$? 1$ from 1.000.000 people online only 1.000$ from 1.000 people A couple phone calls can be spent to close deal 1.000.000$ from 1 person A lot of effort can be spent to close deal ","version":null,"tagName":"h2"},{"title":"Million Subs on Instagram​","type":1,"pageTitle":"How to code","url":"/blog/how_to_code#million-subs-on-instagram","content":"Followers and Influencers. Both need to consent. Convince 1.000.000 others to follow you. Appealing content &quot;Novelty&quot;&quot;Shock&quot;&quot;Beauty&quot;&quot;Sexuality&quot;&quot;Comedy&quot; Be famous FOMO &lt;-- Fear of missing something positive&quot;car crash&quot; &lt;-- Fear of missing out on something negative Dark arts Buy followers Cracked accountsNew accounts Make Instagram private Mystery (Whats behind the curtain?) ","version":null,"tagName":"h2"},{"title":"Wasting time​","type":1,"pageTitle":"How to code","url":"/blog/how_to_code#wasting-time","content":"Existentialism --&gt; You make your own meaning. Don't fall in other people's funnels. Don't be in skinner boxes. Don't be influenced by advertising. What to learn Object level skills, like specific frameworks, or languages, are not that important. They will die out at some point. Meta level skills, like how to learn, are more important. ","version":null,"tagName":"h2"},{"title":"Example Data Science​","type":1,"pageTitle":"How to code","url":"/blog/how_to_code#example-data-science","content":"Learning statistics is more important than learning Pytorch. Statistics will always be useful, but Pytorch will be replaced at some point. ","version":null,"tagName":"h2"},{"title":"Knowledge Tree​","type":1,"pageTitle":"How to code","url":"/blog/how_to_code#knowledge-tree","content":"Integrate new information into the tree. Build a world model. In the case of not knowing something you are still able to make decent decisions based on interpolation. The root of the tree might be something like physics, such that every data point that gets included in your tree can be distilled down to the smallest particles known in physics at the time. This enables predictions about unknown data points. Another tree root, arguably more advanced than physics, is information. This is based on the paradigm from before (Input --&gt; System --&gt; Output). This obviously includes physics as a sub tree. &quot;There are 2 hard problems in computer science: cache invalidation, naming things, and off-by-1 errors.&quot; ","version":null,"tagName":"h2"},{"title":"Leetcode Interviews​","type":1,"pageTitle":"How to code","url":"/blog/how_to_code#leetcode-interviews","content":"Insulting Just shows if you can grind leetcode not if you are intelligent or a good programmer. Programming challenges with an objective metric and a slight time limit. ","version":null,"tagName":"h2"},{"title":"Machine Learning","type":0,"sectionRef":"#","url":"/blog/machine_learning","content":"","keywords":"","version":null},{"title":"Preparation​","type":1,"pageTitle":"Machine Learning","url":"/blog/machine_learning#preparation","content":"Going Through CS50 for refresh of some basics (Notes). ","version":null,"tagName":"h2"},{"title":"Sources​","type":1,"pageTitle":"Machine Learning","url":"/blog/machine_learning#sources","content":"Roadmap/Plan Motivation/Karpathy is a cool dude ","version":null,"tagName":"h2"},{"title":"Problem description​","type":1,"pageTitle":"Machine Learning","url":"/blog/machine_learning#problem-description","content":"Find a model or procedure that makes best use of historical data comprised of inputs and outputs in order to skillfully predict outputs given new and unseen inputs in the future. [1] ","version":null,"tagName":"h2"},{"title":"Problem solution​","type":1,"pageTitle":"Machine Learning","url":"/blog/machine_learning#problem-solution","content":"A model or procedure that automatically creates the most likely approximation of the unknown underlying relationship between inputs and associated outputs in historical data. [1] ","version":null,"tagName":"h2"},{"title":"How to get there​","type":1,"pageTitle":"Machine Learning","url":"/blog/machine_learning#how-to-get-there","content":"","version":null,"tagName":"h2"},{"title":"Define the problem​","type":1,"pageTitle":"Machine Learning","url":"/blog/machine_learning#define-the-problem","content":"Describe problem informally and formally and list assumptions and similar problemsList motivations for solving the problem, the benefits a solution provides and how the solution will be used.Describe how the problem could be solved manually. ","version":null,"tagName":"h3"},{"title":"Prepare Data​","type":1,"pageTitle":"Machine Learning","url":"/blog/machine_learning#prepare-data","content":"Consider what data is available, what data is missing and what data can be removed.Organize your selected data by formatting, cleaning and sampling from it.Transform preprocessed data into features ready for machine learning. ","version":null,"tagName":"h3"},{"title":"Spot check algorithms​","type":1,"pageTitle":"Machine Learning","url":"/blog/machine_learning#spot-check-algorithms","content":"create small experiment with different transformations of the dataset and different standard algorithmsrun every pair a bunch of times and compare mean and variancehelps flushing out the problem structure and getting the algorithms on which to focus in the next steps ","version":null,"tagName":"h3"},{"title":"Improving Results​","type":1,"pageTitle":"Machine Learning","url":"/blog/machine_learning#improving-results","content":"Search through parameter space to find best performing modelsEnsemble: combine results of multiple models ","version":null,"tagName":"h3"},{"title":"Present Results​","type":1,"pageTitle":"Machine Learning","url":"/blog/machine_learning#present-results","content":"Define the context of the problem and the motivationDescribe Problem as a question that got answeredConcisely describe the solution as an answer to the questionSpecify limitations of the model, what questions it can't answer and with what probability it can answer questions Precision and Recall Let's assume we have a dataset of 10 items and some metric with a threshold | beyond witch our correctly classified items should lie. X is the positive class, o is the negative class. To the right of the threshold the positive class is correctly classified, to the left it is not. o o o o o x x | x o x We can then calculate the true positives, false positives, true negatives and false negatives. ","version":null,"tagName":"h3"},{"title":"Confusion Matrix:​","type":1,"pageTitle":"Machine Learning","url":"/blog/machine_learning#confusion-matrix","content":"True Positives (TP): 2 (Number of positive items correctly classified)False Positives (FP): 2 (Number of positive items incorrectly classified)True Negatives (TN): 5 (Number of negative items correctly classified)False Negatives (FN): 1 (Number of negative items incorrectly classified) ","version":null,"tagName":"h2"},{"title":"Performance Metrics:​","type":1,"pageTitle":"Machine Learning","url":"/blog/machine_learning#performance-metrics","content":"Accuracy: (TP + TN) / (TP + TN + FP + FN) = 8/10 Rate of correct classifications. Precision: TP / (TP + FP) = 2/4 Precision is the rate of correctly predicted positives of all predicted positives. Should be high for detecting spam email. You want to let all important emails through, and it's fine if some spam get's through. Recall: TP / (TP + FN) = 2/3 Recall is the rate of correctly predicted positives of all actual positives. Should be high for detecting thiefs. It's important to catch all of them, and fine if you pull out a few normal customers. F1 Score: 2 (Precision Recall) / (Precision + Recall) = 2/3 Harmonic mean of precision and recall. Specificity: TN / (TN + FP) = 5/7 Rate of correct negative classifications. Things to look out for ","version":null,"tagName":"h2"},{"title":"AUC of 1​","type":1,"pageTitle":"Machine Learning","url":"/blog/machine_learning#auc-of-1","content":"AUC can be interpreted as the probability that the model will rank a random positive example higher than a random negative example, which is good.but AUC of 1 indicates a perfect model, which is likely a bug ","version":null,"tagName":"h2"},{"title":"Loss increasing​","type":1,"pageTitle":"Machine Learning","url":"/blog/machine_learning#loss-increasing","content":"BugLearning rate too high always start with low learning rate to check if everything worksthen adjustnot working if loss function plateaus, or start is in a local minimum Overview This should be a high level overview of the field of machine learning. It can help to determine what methods to use for a given problem. In general it's important to know what kind of data there is and what you want to predict. From that you can determine what kind of model, loss function and optimization algorithm to use. Predicting a quantity: Regression Linear RegressionLogistic RegressionSupport Vector MachinesNeural Networks Predicting a category: Classification Logistic RegressionSupport Vector MachinesNeural Networks add base formulas for everything but also add implementations for everything ","version":null,"tagName":"h2"},{"title":"Feature Selection/Engineering​","type":1,"pageTitle":"Machine Learning","url":"/blog/machine_learning#feature-selectionengineering","content":"","version":null,"tagName":"h2"},{"title":"Models​","type":1,"pageTitle":"Machine Learning","url":"/blog/machine_learning#models","content":"","version":null,"tagName":"h2"},{"title":"Loss Functions​","type":1,"pageTitle":"Machine Learning","url":"/blog/machine_learning#loss-functions","content":"Add regularization to loss function ","version":null,"tagName":"h2"},{"title":"Optimization Algorithms​","type":1,"pageTitle":"Machine Learning","url":"/blog/machine_learning#optimization-algorithms","content":"Compute gradients ","version":null,"tagName":"h2"},{"title":"Evaluation Metrics​","type":1,"pageTitle":"Machine Learning","url":"/blog/machine_learning#evaluation-metrics","content":"","version":null,"tagName":"h2"},{"title":"Classification​","type":1,"pageTitle":"Machine Learning","url":"/blog/machine_learning#classification","content":"Accuracy​ accuracy=correctly classified examplestotal examplesaccuracy = \\frac{correctly\\ classified\\ examples}{total\\ examples}accuracy=total examplescorrectly classified examples​ ","version":null,"tagName":"h3"},{"title":"notes","type":0,"sectionRef":"#","url":"/blog/notes","content":"","keywords":"","version":null},{"title":"Destiny notes​","type":1,"pageTitle":"notes","url":"/blog/notes#destiny-notes","content":"Website to organize Destiny's arguments in a nice format with logic structurelink to segments/proofs ","version":null,"tagName":"h2"},{"title":"overarching points​","type":1,"pageTitle":"notes","url":"/blog/notes#overarching-points","content":"All the points are supposed to be examples of the application of a systemThis system is used to generate good outcomes in your liveSo don't try to copy the outcome of the points, as they are based on Destiny's subjective values and environmentInstead try to understand the system and apply it to your own life ","version":null,"tagName":"h3"},{"title":"","type":1,"pageTitle":"notes","url":"/blog/notes##","content":"Act as a sounding board when talking with emotional friendif you have the choice between burning someone to the ground or leaving it neutral, leave it neutralbe really careful when comparing people, especially when both are friends e.g. Comparing body parts ","version":null,"tagName":"h3"},{"title":"AI vs human​","type":1,"pageTitle":"notes","url":"/blog/notes#ai-vs-human","content":"Website with questionneed to select real answer, from real and AI generated answerAI generated answer is instructed to sound like human (gpt3 api) ","version":null,"tagName":"h2"},{"title":"Neural network","type":0,"sectionRef":"#","url":"/blog/neural_network","content":"","keywords":"","version":null},{"title":"Intuitive understanding​","type":1,"pageTitle":"Neural network","url":"/blog/neural_network#intuitive-understanding","content":"A neural network is pretty much just a function that maps a bunch of inputs to a bunch of outputs. First that function does bad at mapping. By showing a lot of input/output pairs the parameters in the function get adjusted to improve the mapping. So there are three big parts of a neural network. The architecture of the network, the optimization of the parameters and the amount and quality of the data. ","version":null,"tagName":"h2"},{"title":"Architecture​","type":1,"pageTitle":"Neural network","url":"/blog/neural_network#architecture","content":"How many layers?What type of layers?What activation functions?Input and output dimensions? ","version":null,"tagName":"h2"},{"title":"Optimization​","type":1,"pageTitle":"Neural network","url":"/blog/neural_network#optimization","content":"What does the loss function look like?Gradient descent?What optimizer?When and how fast to change the parameters?When to stop training?Is there overfitting? ","version":null,"tagName":"h2"},{"title":"Data​","type":1,"pageTitle":"Neural network","url":"/blog/neural_network#data","content":"How much data is there?Is Data argumentation necessary and/or useful?Can there be too much data?Is there bias in data? Practical Stuff ","version":null,"tagName":"h2"},{"title":"Perceptron​","type":1,"pageTitle":"Neural network","url":"/blog/neural_network#perceptron","content":"The Perceptron is the simplest neural network possible. ","version":null,"tagName":"h2"},{"title":"Implement small deep learning library from scratch (with numpy)​","type":1,"pageTitle":"Neural network","url":"/blog/neural_network#implement-small-deep-learning-library-from-scratch-with-numpy","content":"At some point!! To help with a deeper understanding of backpropagation and the inner workings in general. ","version":null,"tagName":"h2"},{"title":"Human Robot Interaction","type":0,"sectionRef":"#","url":"/blog/hri","content":"","keywords":"","version":null},{"title":"Task​","type":1,"pageTitle":"Human Robot Interaction","url":"/blog/hri#task","content":"HRI interface comparisons with examples (VR, AR, bio-signal-based) ","version":null,"tagName":"h2"},{"title":"Comparison VR, AR, Bio-signal-based​","type":1,"pageTitle":"Human Robot Interaction","url":"/blog/hri#comparison-vr-ar-bio-signal-based","content":"Advantage of all of them is that the user can often interact with the robot in a natural way through hand and body gestures. This makes it possible for users without the technical knowledge of controlling the robot traditionally, to control the robot. ","version":null,"tagName":"h2"},{"title":"Virtual reality(VR)​","type":1,"pageTitle":"Human Robot Interaction","url":"/blog/hri#virtual-realityvr","content":"Virtual reality puts a human into a virtual world to interact with a robot. The human can see the robot and the robot can see the human. The human can interact with the robot by using a controller or by using their hands. One important aspect is ability to get almost instant feedback from the robot motion. This is important for the human to be able to learn how to control the robot. VR headsets can often be uncomfortable to wear for long periods of time. Newer headsets have batteries instead of cable connections, which can be better or worse depending on the use case. VR could technically do the save as AR does, by just recording the world around the human and displaying parts of it in VR. However the technology isn't there yet to perfectly display reality, so there is still clearly a difference. Could pre-render the actions given to the robot, before executing them. ","version":null,"tagName":"h3"},{"title":"Augmented reality(AR)​","type":1,"pageTitle":"Human Robot Interaction","url":"/blog/hri#augmented-realityar","content":"Augmented reality enhances the real world around the human with digital information to better interact with a robot. The human can see the robot and the robot can see the human. The human can interact with the robot by using a controller or by using their hands. One difference to VR is the ability to also see and better interact with the real world around the human. ","version":null,"tagName":"h3"},{"title":"Bio-signal-based​","type":1,"pageTitle":"Human Robot Interaction","url":"/blog/hri#bio-signal-based","content":"Bio-signal-based devices can be used to control robots. Many different types of bio-signal-based devices exist, such as EEG, EOG, EMG, ECG, ERG, EGG, GSR and EDA. Electroencephalography (EEG): Measures electrical activity of the brain.Electrooculography (EOG): Measures electrical activity of the eye.Electromyography (EMG): Measures electrical activity of the muscles.Electrocardiography (ECG): Measures electrical activity of the heart.Electroretinography (ERG): Measures electrical activity of the retina.Electroglottography (EGG): Measures electrical activity of the vocal cords.Galvanic skin response (GSR)/Electrodermal activity (EDA): Measures electrical activity of the skin. These devices can be used to control robots in many different ways. For example, a person can control a robot by thinking about moving it, or by moving their eyes to look at different parts of the robot. Bio-signal-based devices can also be used to control robots by measuring the person's heart rate, or by measuring the person's sweat levels. ","version":null,"tagName":"h3"},{"title":"Some abbreviations​","type":1,"pageTitle":"Human Robot Interaction","url":"/blog/hri#some-abbreviations","content":"ROS: Robot Operating System ","version":null,"tagName":"h3"},{"title":"General papers​","type":1,"pageTitle":"Human Robot Interaction","url":"/blog/hri#general-papers","content":"https://link.springer.com/content/pdf/10.1007/s43154-020-00005-6.pdf overview of different HRI interfaces https://graphics.cs.wisc.edu/Papers/2017/LRMG17/roman-vr-2017.pdf general paper about VR as a HRI interface http://ti.rutgers.edu/publications/papers/1999_ieee_tra.pdf paper about using VR for HRIdecent overview of VR https://robotics.mit.edu/teleoperating-robots-virtual-reality MIT article https://www.allerin.com/blog/ar-vr-and-other-ways-of-controlling-robots article about different HRI interfacesmight be perfect overview https://www.mdpi.com/1424-8220/21/20/6863 huge summary/survey of bio-signal-based solutionsfor assistance/rehabilitation https://arxiv.org/pdf/2203.03254.pdf AR summary2022 paper ","version":null,"tagName":"h3"},{"title":"General comparisons​","type":1,"pageTitle":"Human Robot Interaction","url":"/blog/hri#general-comparisons","content":"https://reader.elsevier.com/reader/sd/pii/S2212827120314815?token=674B622691122E381C72A6FD9A55D0F0163342C7E2F3F3785601BAECC912EB05ED29318E11A2834A7D0B9019B9EE27A6&amp;originRegion=eu-west-1&amp;originCreation=20221104125245 Review of VR/AR solutions for HRI https://cs.brown.edu/people/er35/publications/SIEDS_2020.pdf comparison of different VR approachespositional control (waypoint navigation)trajectory control (click and drag) ","version":null,"tagName":"h3"},{"title":"get at least one paper with an example for every interface type (VR, AR, bio-signal-based)​","type":1,"pageTitle":"Human Robot Interaction","url":"/blog/hri#get-at-least-one-paper-with-an-example-for-every-interface-type-vr-ar-bio-signal-based","content":"VR​ https://arxiv.org/pdf/1903.10064.pdf controlling a swarm of robots with VRmanipulating the environment in VR, zooming in and outplacing walls in the environment to block the robotshighlights intuitiveness of VRgestures are intuitive, but need some trainingvisual information from the robots gets sent to pc and dynamically rendered in VRtechnically human swarm interaction (HSI)summary: VR is used in \\cite to control a swarm of robots. The robots are able to navigate and interact with each other on their own. The user can use VR to manipulate the environment, zoom in and out, and place walls in the environment to block or guide the robots. Additionally the robots can be picked up and placed in a new location. Leap Motion is used to identify the users motions. Thus the user can propose future actions or locations in the virtual environment and the robots will try to execute or move to them in the real world. The authors conducted a usability study with 10 participants between the ages 20 and 35 with an engineering background. Is showed that the controls are intuitive and the test missions are accelerated with the help of human intervention. They note however that some of the gestures, specifically the wall placement and the world resizing, need some training to get used to. https://h2r.cs.brown.edu/wp-content/uploads/whitney18.pdfhttps://cs.brown.edu/people/gdk/pubs/vr_teleop.pdf controlling robots over the internet with VR (teleoperation)created interface to be used by other researcherscan be used with consumer-grade headsetstesting approach: https://cs.brown.edu/people/er35/publications/testing.pdf establishes baseline for other research https://arxiv.org/pdf/1703.01270.pdf control of robot arms in VRVR Control Roomhighlights collocation capabilities of VRpick, place, assembly, manufacturing taskssummary: In \\cite a team of researchers use VR to control a robot arm. The robot has two arms and is equipped with a camera at its &quot;head&quot;. The user uses the consumer-grade headset Oculus Rift CV1 and two Razer Hydra hand trackers as controllers. In VR the robot can then be controlled from a control room, which includes the view of the main camera and two optional views from the two robot arms. So the user feels as if they were in the robots head. To test the system, the authors made an expert user pick up and assemble a Lego piece. They compared it to an automated algorithm on the same task and were able to show that the human performed perfect, whereas the algorithm showed some weakness on the assembly. The user reported that the cameras in the robot arms helped with the alignment of the pieces. The teleoperation allows the user to perform actions from a save environment. The paper highlights the ability of VR to utilize consumer-grade hardware. AR​ https://www.frontiersin.org/articles/10.3389/frobt.2017.00020/full uses tabletdisplays information about the robots motion on the tabletone tiltable camera, 1/3 of workspace visible at a timeuses the tablet to control the robot3 interfaces: control with accelerometer of tablet egocentric: user sees the workspace from the robots perspective. Parts of the workspace are not observable due to the lack of field of view and movement of the camera.exocentric: user sees the workspace from a fixed position on the ceiling. Vision under the robot arm is blocked, so some objects can't be interacted with.mobile mixed reality: user sees workspace from tablet in arbitrary position. Can access any location. pretrial (place one box somewhere else) was easier with AR plot over workspace enabledmobile performs bestarticle about it: https://thenewstack.io/smartphone-app-can-control-robots-augmented-reality/summary: AR can be used to enhance the environment. In \\cite the authors compare 3 interfaces. One egocentric, with a tiltable camera on the robots head, one exocentric, with the camera on the ceiling looking down, and the proposed method of using a mobile tablet as the camera. All three approaches use the tablets accelerometer to control the robots arms. The main advantage of the proposed method is, that its cameras field of view can reach all places, unlike the other two. The users can see an overlay over the workspace on the tablet screen, where the robots maximum range of motion and potential actions can be projected. When testing the system, users performed better on the pretrial, when having the AR plot enabled. Additionally the mobile reality interface shows better performance than the other two. The main points to take away, are that this approach needs visual markers in the environment, the user and the robot need to be in the same environment for the mobile version and the AR overlay helps the user and the robot interact better. Bio-signal-based​ https://link.springer.com/article/10.1007/s10514-020-09916-x earlier work used only EEG: http://groups.csail.mit.edu/drl/wiki/images/e/ec/Correcting_Robot_Mistakes_in_Real_Time_Using_EEG_Signals.pdfUses EMG(muscle) + EEG(brain) to give swift feedback to robotEMG is used to detect the users intention, EEG is used to detect potential errors the robot or the human makessummary: In the paper \\cite the authors used a hybrid of electromyography (EMG) and electroencephalography (EEG) to control a arm with a tool on it. The robot was supposed to hit one of three holes in the wall in front of it with the electric screwdriver in their hand. The user is equipped with electrodes on their head and surface bar electrodes are applied to their forearms. The signals of those devices are processed separately and then used to determine the action of the robot arm. The user observes the robot and its environment directly and tries to move the tool in the robots hand via muscle movements. When the robot or the user themself make a mistake, the users brain reacts a certain way, often unconsciously, which can be detected by the EEG processor. Those signals are then used to stop and then correct the robot. The system was evaluated on 7 participants. The users were untrained, to reduce the hurdle for new users. The correct target was hit in roughly 70% of the trials, when the robot randomly chose. With the help of the correction through the participant, the success rate jumped to 97%. The authors concluded, that the reliability needs to be improved to be able to deploy the system in safety critical situations. Specifically, the neural network that classified the EEG signal into mistake or no-mistake, had only a 54% accuracy. They also highlight that more users would be needed to make the system more robust towards inter-person variations. However, the system shows potential for an effective supervision system. https://www.jmir.org/2019/10/e16194/ neuralink whitepaperuses brain signals to control a robotmight be interesting, but not used on humans yetdon't know if it &quot;counts&quot; as an examplemainly describes a way to get information out of the human brain, not however how to interpret it or control a robot.but really important https://static.aminer.org/pdf/PDF/000/329/658/emg_based_human_machine_interface_system.pdf example of using EMG to control a robotreally old paper ","version":null,"tagName":"h3"},{"title":"Comparison​","type":1,"pageTitle":"Human Robot Interaction","url":"/blog/hri#comparison","content":"AR is the cheapest of the three, as no special hardware is needed most of the time. VR however has huge upside of remote operation, by emerging the user in the distant environment. Additionally VR can be more intuitive because the user can be &quot;in the skin&quot; of the robot. Bio-signal-based solutions are in the early stages but offer huge potential for swift intuitive interaction with robots. \tExample use cases\tExample devices\tease of use\tunique functions\tcost\tfuture potentialVR\tcontrol robot motion over internet by moving controllers and observing results\tOculus rift, Meta quest pro, smartphone\tspecial equipment necessary (headset and controllers), often uncomfortable for long periods of time, either battery (limited work time) or cables (limited motion range)\tteleoperation, see whole environment of the robot from somewhere else; ego perspective and feel of robot (step into skin of robot, more hands on), but strong stable internet connection necessary\texpensive special equipment, getting cheaper when consumer grade equipment can be used\tmight become important to remotely help out &quot;almost fully&quot; autonomous systems in difficult situations; need better form factors AR\tdisplay important robot information about the robot(range of motion, wear and tear, pre-rendering of action)\tgoogle glasses, tablet, smartphone\treally simple\tno special equipment required\tpretty low, no special equipment\tintegration into normal glasses, or contact lenses Bio-signal-based\tsignal if robot did right or wrong action directly with ones mind, control of prosthesis via muscle signals(EMG)\timplants (Neuralink), EEG, EMG, etc.\tsome special equipment needed, sometimes easy to use (wrist bands), sometimes permanent augment (implant)\tif implemented well, can read the humans mind and make robot smooth extension of human\tranges from cheap(wrist bands) to expensive(implants)\thuge potential to merge with robots and full control of a robot with a humans thoughts ","version":null,"tagName":"h2"},{"title":"Use cases​","type":1,"pageTitle":"Human Robot Interaction","url":"/blog/hri#use-cases","content":"VR teleoperationswarm operationfull birds eye view or different perspective AR display important information about the environment and the robot Bio-signal-based control of robotpossibly more complex, and faster controls possible Comparison VR has the special property that it can transport the user into a completely different environment to control a robot through teleoperation. Additionally one can view the environment from any perspective, for example a birds eye view, as in \\ref. This can help to gain an overview over the environment and thus control swarms or other robots. AR and bio-signal-based technologies have direct visual contact from the user or through the camera of a handheld device, like a tablet \\ref, most of the time. However, AR can enhance the real environment with important information about the workspace and the robot. This can help the user to perform the tasks faster and saver. It is to be noted that technically VR can do the same, by recording the environment with its front camera and displaying the information in the headset, but the user might have a lower field of view compared to AR glasses or a tablet. Bio-signal-based technologies can be used to control the robot directly with ones mind (EEG) or muscles (EMG), like in \\ref. The applications are still limited to simple controls of robot arms or the detection of mistakes with the human mind. The main difference to AR and VR is the fact that the reactions can be faster as the thinking about the mistake can be detected unconsciously by the system. The main issue is that the reliability is still low and thus not save to use with big and powerful robots. ","version":null,"tagName":"h3"},{"title":"Devices​","type":1,"pageTitle":"Human Robot Interaction","url":"/blog/hri#devices","content":"VR Meta quest 2smartphone AR google glassestabletsmartphone Bio-signal-based EEGEMGimplants (Neuralink) Comparison VR devices are mostly headsets to display the environment with controllers to control the robot and the position of the user. For headsets, the Meta Quest 2/Pro or the Valve Index can be used. For the controllers, Razer Hydra hand trackers or the default VR controllers that come with the headsets are available. The user can also use a smartphone as a headset, but the field of view is limited, the performance might not be enough and the resolution is not as good as with a dedicated headset. For AR, dedicated glasses are still early in the development. However handheld devices like tablets or smartphones can be used as well, as in \\ref. Bio-signal-based devices can be wrist bands, that measure muscle contraction, electrodes on the scalp to measure signals from the brain or various other specialized technology. One main difference is that VR and AR devices are bought on the consumer market, which can help with cost and development, whereas bio-signal-based devices aren't often used in everyday live. ","version":null,"tagName":"h3"},{"title":"Ease of use​","type":1,"pageTitle":"Human Robot Interaction","url":"/blog/hri#ease-of-use","content":"VR special equipment necessary (headset and controllers), often uncomfortable for long periods of time, either battery (limited work time) or cables (limited motion range)intuitive, ego perspective AR really simpleneed to control by touchscreen, which is not as intuitive as VR Bio-signal-based some special equipment needed, sometimes easy to use (wrist bands), sometimes permanent augment (implant) comparison ","version":null,"tagName":"h3"},{"title":"Cost​","type":1,"pageTitle":"Human Robot Interaction","url":"/blog/hri#cost","content":"Table: technology\tdevice\tcost\tlinkVR\tMeta Quest 2\t450$\thttps://www.meta.com/de/en/quest/products/quest-2/ VR\tValve Index\t1079$\thttps://store.steampowered.com/valveindex AR\tI-pad\t449$\thttps://www.apple.com/shop/buy-ipad/ipad AR\tGalaxy Tab S8\t200$\thttps://www.samsung.com/us/tablets/galaxy-tab-s8/buy/ AR\tGoogle Glasses\t999$\thttps://www.theverge.com/2019/5/20/18632689/google-glass-enterprise-edition-2-augmented-reality-headset-pricing Bio-signal-based\tEEG electrode hat\t1500$\thttps://shop.openbci.com/collections/frontpage comparison To compare the cost of the different technologies, The prices of the different devices were looked up and summarized in \\ref. Note that this is only a fraction of possible devices. The low end Meta Quest 2 in the same price range as the high end I-Pad. But when comparing the more powerful Valve Index, to a more budget tablet, like the Galaxy Tab S8, VR devices are considerably more expensive than a basic AR device. Additionally for most VR headsets, an additional high end PC is necessary to process the visuals. Another alternative for AR are the Google Glasses, which come at a higher price, similar to the VR headsets. Bio-signal-based devices, specifically EEG, are starting at the price of a VR headset. They might however get cheaper if those devices get produced in higher numbers. The prices can get way higher as well, if implants through operations are used. So in general, AR is the cheapest option, as one can simply use a smartphone or a tablet. VR requires some special technology in form of a headset and probably a high end PC. Finally, the bio-signal-based devices come out as most expensive, as they are still early in development. ","version":null,"tagName":"h3"},{"title":"Problems​","type":1,"pageTitle":"Human Robot Interaction","url":"/blog/hri#problems","content":"The main ways VR and AR can improve from today are general hardware improvements like better batteries, ","version":null,"tagName":"h3"},{"title":"Future potential​","type":1,"pageTitle":"Human Robot Interaction","url":"/blog/hri#future-potential","content":"VR might become important to remotely help out &quot;almost fully&quot; autonomous systems in difficult situationsneed better form factors and better hardware: batteriesmore comfortable AR integration into normal glasses, or contact lensesmore powerful hardware, or remote processing Bio-signal-based huge potential to merge with robots and full control of a robot with a humans thoughtsmore consumer based hardwareimproved reliability Comparison: VR might be used at some point to have the human help out almost fully autonomous systems by stepping in the perspective of the robot. Or it can be used to fully control robots remotely and remove the need for humans to work in dangerous environments. AR could have a huge jump in usability if it were to be integrated into everyday glasses or even contact lenses. This could enable people without training to use them. If robots are more common in everyday life this might increase the trust in the robots by displaying certain information about the robots future actions in the environment. Bio-signal-based technologies could be used to completely and reliably control robots with human thoughts, which would be a huge step in the field of human-robot interaction. If this technology is achieved, most other control devices might be obsolete. So the biggest potential certainly lies within EEG technologies, as they can enable a direct link between human and robot. However the other two technologies might also play a crucial role in some more niche cases. ","version":null,"tagName":"h3"},{"title":"Conclusion​","type":1,"pageTitle":"Human Robot Interaction","url":"/blog/hri#conclusion","content":"Summarize the key points and findings of the paper: In summary, it is difficult to compare the three technologies, because they each have their different use cases, as seen in \\ref. Additionally, they are never tested against each other, with regard to user feedback. When comparing the use cases, VR shows a clear advantage in teleoperation, AR in merging digital information into the real world environment and bio-signal-based technology can use quick reactions directly from the human brain to mitigate mistakes. Highlight the main contributions of the paper and its impact on the field of HRI interfaces: This paper compares some examples of the three technologies and their use cases. It also extrapolates those comparisons to the whole categories. Hopefully it can give some ideas on the future research directions of the field. Additionally, this is an encouragement to further investigate how to better compare the three technologies to then be able to better predict what technology is worth more efforts. To conclude this report, some recommendations for future research are the following. Discuss future directions for research in HRI interfaces, including VR, AR, and bio-signal-based: The final achievement would be to have a direct link between human and robot in both directions. Until then, all three technologies will need to be improved gradually. For VR, the ability to wear the headset for a long time and training programs should be the focus. AR might be more useful, if the technology gets integrated better into glasses to not need an extra tablet while working with a robot in the workspace. Bio-signal-based technologies first need to improve their reliability before they can be used in real-world applications. A next step would be to improve the designs behind the devices, so they can be used more for consumer products and accelerate the development. ","version":null,"tagName":"h2"},{"title":"todo​","type":1,"pageTitle":"Human Robot Interaction","url":"/blog/hri#todo","content":"add picture maybeadd VR/AR review ","version":null,"tagName":"h2"},{"title":"PyTorch","type":0,"sectionRef":"#","url":"/blog/pytorch","content":"","keywords":"","version":null},{"title":"Data Loading​","type":1,"pageTitle":"PyTorch","url":"/blog/pytorch#data-loading","content":"For a custom dataset one needs to implement the Dataset class even if its the most basic dataset. ","version":null,"tagName":"h2"},{"title":"Derivatives​","type":1,"pageTitle":"PyTorch","url":"/blog/pytorch#derivatives","content":" ","version":null,"tagName":"h2"},{"title":"Regression","type":0,"sectionRef":"#","url":"/blog/regression","content":"Regression tries to find the parameters of a function that represents the relationship between input and output variables with the least amount of error.","keywords":"","version":null},{"title":"ML Glossary","type":0,"sectionRef":"#","url":"/blog/ml_glossary","content":"","keywords":"","version":null},{"title":"L1 Regularization​","type":1,"pageTitle":"ML Glossary","url":"/blog/ml_glossary#l1-regularization","content":"Penalizing the absolute value of the weights in a model. Compared to the L2 regularization, the weights can now drop to zero and thus can be removed from the model. Maths The L1 regularization term is of the form L1=λ∑i=1n∣wi∣L_1 = \\lambda \\sum_{i=1}^n |w_i|L1​=λ∑i=1n​∣wi​∣, where λ\\lambdaλ is the regularization parameter, which controls how much regularization there should be, and wiw_iwi​ is the i thi\\,\\text{th}ith weight. Implementation In pytorch we can loop over all the parameters and add their absolute values to the loss function. loss_reg_l1 = 0 for param in model.parameters(): loss_reg_l1 += torch.sum(torch.abs(param)) total_loss = loss_data + lambda * loss_reg_l1 In sklearn, most models, like the SGDClassifier, have a penalty parameter that can be set to 'l1' to use L1 regularization. And the alpha parameter that controls the lambda. clf = SGDClassifier(penalty='l1', alpha=0.01)  ","version":null,"tagName":"h2"},{"title":"One-hot Encoding​","type":1,"pageTitle":"ML Glossary","url":"/blog/ml_glossary#one-hot-encoding","content":"A way to represent categorical features as binary features. Example Let's say we have a dataset with a feature weather that can take on the values sunny, cloudy and rainy. We can one-hot encode this feature as [1, 0, 0] for sunny, [0, 1, 0] for cloudy and [0, 0, 1] for rainy. Thus we created three binary features from one categorical feature. ","version":null,"tagName":"h2"},{"title":"L2 Regularization​","type":1,"pageTitle":"ML Glossary","url":"/blog/ml_glossary#l2-regularization","content":"L2 Regularization can be used to punish large weights in a model. Large model weights often indicate more complex models that are more prone to overfitting. Thus overfitting can be reduced by driving all the weights towards zero, but not exactly zero. Maths L2 Regularization adds a term to the loss function of the form L2=λ∑i=1nwi2L_2 = \\lambda \\sum_{i=1}^n w_i^2L2​=λ∑i=1n​wi2​, where λ\\lambdaλ is the regularization parameter, which controls how much regularization there should be, and wiw_iwi​ is the i thi\\,\\text{th}ith weight. We can see that the derivative of the L2 regularization term is 2wi2 w_i2wi​, thus the smaller the weight, the smaller the push towards zero by the parameter update. So the weights almost never reach exactly zero (unless floating point stuff). Implementation In pytorch, we can use the weight_decay parameter in the optimizer to change the lambda of L2 regularization. optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.01) In sklearn, most models, like the SGDClassifier, have a penalty parameter that can be set to 'l2' to use L2 regularization. And the alpha parameter that controls the lambda. clf = SGDClassifier(penalty='l2', alpha=0.01)  ","version":null,"tagName":"h2"},{"title":"Sparse Feature​","type":1,"pageTitle":"ML Glossary","url":"/blog/ml_glossary#sparse-feature","content":"A feature that is mostly zero across all observations and is therefore sparse in the sense that it has few non-zero values. For example, a dataset of people and their favorite songs might have a feature for each song of 100000 songs. However, most people have only listened to a few songs, so most of the feature values would be zero and some ones (one-hot encoding). ","version":null,"tagName":"h2"},{"title":"Feature Cross​","type":1,"pageTitle":"ML Glossary","url":"/blog/ml_glossary#feature-cross","content":"A new feature that is created by combining two or more existing features. This is often used to create non-linearity in a linear model. Example So for example, we can have the feature xxx and a non-linear relationship to yyy. Instead of using a non-linear model, we can create a new feature x2x^2x2 and use a linear model. Implementation In pandas, one can just add another column to the dataframe with the new feature. df['x_squared'] = df['x'] ** 2  ","version":null,"tagName":"h2"},{"title":"Activation Function​","type":1,"pageTitle":"ML Glossary","url":"/blog/ml_glossary#activation-function","content":"A function that is applied to the output of a layer/neuron in a model. It is mainly used to introduce non-linearity to the otherwise linear model. Popular examples are the sigmoid function, the tanh function and the ReLU function. The ReLU function often works better than the other two smooth functions and is easier to compute. This is mostly based on empirical evidence. In general, any mathematical function can be used as an activation function. However it is important that the function is differentiable, because we need to compute the derivative of the function for the backpropagation algorithm. Maths The sigmoid function is defined as σ(x)=11+e−x\\sigma(x) = \\frac{1}{1 + e^{-x}}σ(x)=1+e−x1​. The tanh function is defined as tanh⁡(x)=ex−e−xex+e−x=e2x−1e2x+1\\tanh(x) = \\frac{e^x - e^{-x}}{e^x + e^{-x}} = \\frac{e^{2x} - 1}{e^{2x} + 1}tanh(x)=ex+e−xex−e−x​=e2x+1e2x−1​. The ReLU function is defined as ReLU(x)=max⁡(0,x)\\text{ReLU}(x) = \\max(0, x)ReLU(x)=max(0,x). Implementation In pytorch, we can add the activation functions to the model definition. (ReLU,Sigmoid,Tanh) import torch.nn as nn x = torch.randn(1, 1) m = nn.ReLU() m = nn.Sigmoid() m = nn.Tanh() y = m(x) or functional (ReLU,Sigmoid,Tanh) import torch.nn.functional as F x = torch.randn(1, 1) y = F.relu(x) y = F.sigmoid(x) y = F.tanh(x) In sklearn, we can specify the activation function for each model in the model definition, for example for the MLPClassifier. clf = MLPClassifier(activation='relu') clf = MLPClassifier(activation='logistic') clf = MLPClassifier(activation='tanh') The logistic activation function is the sigmoid function in this case. The sigmoid function is a special case of the logistic function. ","version":null,"tagName":"h2"},{"title":"Neural Network​","type":1,"pageTitle":"ML Glossary","url":"/blog/ml_glossary#neural-network","content":"A neural network is a model that consists of multiple layers of neurons. In general, a neural network consists of an input layer, whose dimensions fits the input data (features)one or more hidden layers, with weights/biases as connections and an activation functionan output layer, whose dimensions fits the output data (labels) Implementation In pytorch, we can define a neural network by subclassing the nn.Module class. import torch.nn as nn class Net(nn.Module): def __init__(self): super(Net, self).__init__() self.fc1 = nn.Linear(10, 20) self.fc2 = nn.Linear(20, 1) self.relu = nn.ReLU() def forward(self, x): x = self.fc1(x) x = self.relu(x) x = self.fc2(x) return x  ","version":null,"tagName":"h2"},{"title":"Vanishing Gradient​","type":1,"pageTitle":"ML Glossary","url":"/blog/ml_glossary#vanishing-gradient","content":"The gradient during backpropagation may vanish, i.e. approach zero, in the first few layers of a neural network if it is multiplied by low values in the deeper layers. This makes it hard to train earlier layers. In practice the ReLU activation function helps with this problem as it has a derivative of 1 compared to the sigmoid and tanh activation functions, which have very low derivatives pretty quickly. We need to be careful with ReLU, as it's gradient is zero for negative values, which can lead to dead ReLUs. This is further investigated in this paper and can be fixed with a LeakyReLU, which has a linear function with a really small slope for the negative part of the ReLU, so it &quot;leaks&quot; some gradient. ","version":null,"tagName":"h2"},{"title":"Dead ReLU​","type":1,"pageTitle":"ML Glossary","url":"/blog/ml_glossary#dead-relu","content":"A ReLU neuron is dead if it's output is always zero. This can happen if the weights are initialized in a way that the neuron always outputs a negative value. Or in general, if the ReLU unit outputs a negative value it's gradient is zero and it will never be updated. Thus it may never again output a positive value again and contribute to the model. Lowering the learning rate can keep ReLUs from dying. ","version":null,"tagName":"h2"},{"title":"Exploding Gradient​","type":1,"pageTitle":"ML Glossary","url":"/blog/ml_glossary#exploding-gradient","content":"The gradient during backpropagation may explode, i.e. approach infinity, in the first few layers of a neural network if it is multiplied by high values in the deeper layers. This can be fixed by clipping the gradient, batch normalization or a lower learning rate. ","version":null,"tagName":"h2"},{"title":"Dropout​","type":1,"pageTitle":"ML Glossary","url":"/blog/ml_glossary#dropout","content":"Dropout is a regularization technique that randomly sets some neurons to zero during training. This forces the model to learn a more robust representation of the data and prevents overfitting. During inference, all neurons are used again. In practice, there will be a probability ppp attached to certain neurons, which determines if the neuron will be active or not. We can then vary the probability ppp to add more (higher ppp) or less (lower ppp) regularization. Implementation In pytorch, we can add dropout layers to the model definition. import torch.nn as nn class Net(nn.Module): def __init__(self): super(Net, self).__init__() self.fc1 = nn.Linear(10, 20) self.fc2 = nn.Linear(20, 1) self.relu = nn.ReLU() self.dropout = nn.Dropout(p=0.5) def forward(self, x): x = self.fc1(x) x = self.relu(x) x = self.dropout(x) x = self.fc2(x) return x In sklearn we need a custom implementation for a dropout layer. ","version":null,"tagName":"h2"},{"title":"Tidy data","type":0,"sectionRef":"#","url":"/blog/tidy_data","content":"","keywords":"","version":null},{"title":"Melting​","type":1,"pageTitle":"Tidy data","url":"/blog/tidy_data#melting","content":"Turns multiple columns that are variables into a column with the names of the specific columns and a column with the value. ","version":null,"tagName":"h2"},{"title":"Messy:​","type":1,"pageTitle":"Tidy data","url":"/blog/tidy_data#messy","content":"row\ta\tb\tcA\t1\t4\t7 B\t2\t5\t7 C\t3\t6\t9 ","version":null,"tagName":"h3"},{"title":"Molten:​","type":1,"pageTitle":"Tidy data","url":"/blog/tidy_data#molten","content":"row\tcolumn\tvalueA\ta\t1 A\tb\t4 A\tc\t7 B\ta\t2 B\tb\t5 B\tc\t8 C\ta\t3 C\tb\t6 C\tc\t9 ","version":null,"tagName":"h3"},{"title":"String splitting​","type":1,"pageTitle":"Tidy data","url":"/blog/tidy_data#string-splitting","content":"","version":null,"tagName":"h2"},{"title":"Casting​","type":1,"pageTitle":"Tidy data","url":"/blog/tidy_data#casting","content":"","version":null,"tagName":"h2"},{"title":"Search","type":0,"sectionRef":"#","url":"/blog/search","content":"","keywords":"","version":null},{"title":"Linear Search​","type":1,"pageTitle":"Search","url":"/blog/search#linear-search","content":"Just look through every entry from left to right and check if the entry is equal to the target. def linear(input, target): for idx, entry in enumerate(input): if entry == target: return idx return -1  Complexity: O(n)O(n)O(n) Ω(1)\\Omega(1)Ω(1) ","version":null,"tagName":"h2"},{"title":"Binary Search​","type":1,"pageTitle":"Search","url":"/blog/search#binary-search","content":"Only works with a sorted list! Look at the middle of the list first and check if that entry is the target. If it isn't the target, compare that number with the target. If the target is higher, repeat from the first step with the right half of the list, otherwise with the left half. def binary(input, target, idx = None): length = len(input) if length == 0: return -1 middle = length//2 if idx == None: idx = middle if input[middle]==target: return idx if input[middle]&gt;target: return binary(input[:middle], target, idx-((middle//2)+1)) else: return binary(input[middle+1:], target, idx+((middle//2)+1))  Complexity: O(log⁡n)O(\\log n)O(logn) Ω(1)\\Omega(1)Ω(1) ","version":null,"tagName":"h2"},{"title":"Sorting​","type":1,"pageTitle":"Search","url":"/blog/search#sorting","content":"Now the question is: Is it better to just do linear search or sort the array and then do binary search. For one search linear search would make more sense. However in practice the same arrays often get searched multiple times. So it is better to sort them once and then do binary search multiple times on the sorted array to save time. Some Sort Algorithms. ","version":null,"tagName":"h2"},{"title":"Welcome","type":0,"sectionRef":"#","url":"/docs/","content":"Welcome Hi, this is my website!","keywords":"","version":"Next"},{"title":"Sort","type":0,"sectionRef":"#","url":"/blog/sort","content":"","keywords":"","version":null},{"title":"Selection sort​","type":1,"pageTitle":"Sort","url":"/blog/sort#selection-sort","content":"Go through whole list and find the lowest number. Swap that number with the first number in the list. Start with one position to the right and repeat. def selection(input): for i in range(len(input)): min_idx = i for j in range(i,len(input)): if input[j] &lt; input[min_idx]: min_idx = j input[i], input[min_idx] = input[min_idx], input[i] return input  Complexity: O(n2)O(n^2)O(n2) Ω(n2)\\Omega(n^2)Ω(n2) ","version":null,"tagName":"h2"},{"title":"Bubble sort​","type":1,"pageTitle":"Sort","url":"/blog/sort#bubble-sort","content":"Go through list and check if number is higher than the following number. If yes, swap the two numbers. If no, go to the next number. Repeat from the first step, but end one further position to the left. def bubble(input): for i in range(len(input)): for j in range(len(input)-i-1): if input[j] &gt; input[j+1]: input[j], input[j+1] = input[j+1], input[j] return input  Complexity: O(n2)O(n^2)O(n2) Ω(n)\\Omega(n)Ω(n) ","version":null,"tagName":"h2"},{"title":"Merge sort​","type":1,"pageTitle":"Sort","url":"/blog/sort#merge-sort","content":"Divide list in middle and recursively repeat for left and right. When a list is only 1 number return it. When two of these lists got returned, they are sorted. Then they are combined again, by looking at the first entry in each list and appending the lower number to the result. Repeat until right and left are &quot;empty&quot;. def merge(input): if len(input)==1: return input middle = len(input)//2 left, right = input[:middle], input[middle:] left = merge(left) right = merge(right) result=[] i = j = 0 while i &lt; len(left) and j &lt; len(right): if left[i]&lt;right[j]: result.append(left[i]) i+=1 else: result.append(right[j]) j+=1 if i &lt; len(left): result += left[i:] if j &lt; len(right): result += right[j:] return result  Complexity: \\(O(n \\log n)\\) \\(\\Omega(n \\log n)\\) ","version":null,"tagName":"h2"},{"title":"Visualization​","type":1,"pageTitle":"Sort","url":"/blog/sort#visualization","content":"Here. ","version":null,"tagName":"h2"},{"title":"Knowing the unknown","type":0,"sectionRef":"#","url":"/blog/unknown","content":"Why are people often times so bad when they don't have all information. And cant deal with probabilities.","keywords":"","version":null}],"options":{"id":"default"}}