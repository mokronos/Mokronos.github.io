"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[1477],{10:e=>{e.exports=JSON.parse('{"blogPosts":[{"id":"/bayesian_thinking","metadata":{"permalink":"/blog/bayesian_thinking","source":"@site/blog/bayesian_thinking.md","title":"Bayesian thinking","description":"","date":"2023-09-23T15:55:21.000Z","formattedDate":"September 23, 2023","tags":[],"readingTime":0,"hasTruncateMarker":false,"authors":[],"frontMatter":{"layout":"base","title":"Bayesian thinking"},"nextItem":{"title":"classes","permalink":"/blog/classes"}},"content":""},{"id":"/classes","metadata":{"permalink":"/blog/classes","source":"@site/blog/classes.md","title":"classes","description":"erledigt:","date":"2023-09-23T15:55:21.000Z","formattedDate":"September 23, 2023","tags":[],"readingTime":0.5,"hasTruncateMarker":false,"authors":[],"frontMatter":{},"prevItem":{"title":"Bayesian thinking","permalink":"/blog/bayesian_thinking"},"nextItem":{"title":"Coding","permalink":"/blog/coding"}},"content":"erledigt:\\n25: alle kernmodule hab ich (dig \xfcbertragung und dig signalverarbeitung noch nicht bestanden, hochfrequenztechnik noch aus bachelor)\\n\\n25: conv opt, antennen, kanalcodierung, mobile communications, global nav\\n\\n2.5: wahl aus angebot von fau (einf\xfchrung in ML)\\n\\n2.5: hauptseminar aus studienrichtung gemacht (audio processing)\\n\\n\\nlaufend:\\n2.5 laborpraktikum aus studienrichtung (signal processing ML)\\n\\nfehlen:\\nVorlesungen:\\n5 vertiefung (hochfrequenztechnik?)\\n12.5 wahl aus fau\\n\\nPraktika und seminare:\\nhauptseminar aus fau\\n2.5 laborpraktikum aus angebot von techfak\\n2.5 hauptseminar aus angebot von fau\\n10 forschungspraktikum\\n\\n30 fehlen an masterarbeit\\n\\n**************************\\n\\ntotal:\\nerledigt:\\n55 \\nlaufend:\\n2.5\\nbrauch noch:\\n17.5 (vorlesungen)\\n15 (praktika/sem)\\n30 (masterarbeit)\\n-------\\n120"},{"id":"/coding","metadata":{"permalink":"/blog/coding","source":"@site/blog/coding.md","title":"Coding","description":"Gitignore","date":"2023-09-23T15:55:21.000Z","formattedDate":"September 23, 2023","tags":[],"readingTime":0.41,"hasTruncateMarker":false,"authors":[],"frontMatter":{"layout":"base","title":"Coding"},"prevItem":{"title":"classes","permalink":"/blog/classes"},"nextItem":{"title":"CS50","permalink":"/blog/cs50"}},"content":"## Gitignore\\n\\nJust select a gitignore template when creating a repository on github. Overview can be found [here](https://github.com/github/gitignore).\\n\\n\\n## Python random seed\\n\\nNeed to set the seed in the file of the execution of the function. If the function is imported from another file, the seed will not be set for the imported function. Same for PyTorch.\\n\\n## Vim tips\\n\\n- gf to open file under cursor (markdown internal links)\\n- gx to open file under cursor with default program (images, urls)"},{"id":"/cs50","metadata":{"permalink":"/blog/cs50","source":"@site/blog/cs50.md","title":"CS50","description":"Lecture 0","date":"2023-09-23T15:55:21.000Z","formattedDate":"September 23, 2023","tags":[],"readingTime":7.345,"hasTruncateMarker":false,"authors":[],"frontMatter":{"title":"CS50","layout":"base"},"prevItem":{"title":"Coding","permalink":"/blog/coding"},"nextItem":{"title":"Daily ToDos","permalink":"/blog/daily"}},"content":"## [Lecture 0](https://cs50.harvard.edu/college/2022/spring/notes/0/)\\n## [Lecture 1](https://cs50.harvard.edu/college/2022/spring/notes/1/)\\n\\n### Compiling\\n\\n    make <program_name>\\n\\nWith file ending.\\n\\n\\nMake can be used to compile most files. Then one can execute them without file ending.\\n\\n    ./<program_name>\\n\\n### Basic C syntax\\n\\nNo need to go over this.\\n\\n## [Lecture 2](https://cs50.harvard.edu/college/2022/spring/notes/2/)\\n\\n### Some more compiling\\n\\nMake is essentially calling the language specific compilers. For C clang is called. With clang includes need to be manually added as an argument. Make does this automatically.\\n\\nCompiling is generally done in multiple steps:\\n1. Preprocessing:\\n    - adding in includes and macros\\n    - removing comments\\n2. Compiling\\n    - converts code to assembly\\n3. Assembling\\n    - converts assembly to binary, which is machine code and can be run on a CPU.\\n4. Linking\\n    - puts compiled includes in the binary code. No need to compile includes multiple times.\\n\\n### Debugging\\n\\nBugs are errors in a program, so that it performs differently than expected. Finding and fixing these errors is called Debugging.\\n\\n## [Lecture 3](https://cs50.harvard.edu/college/2022/spring/notes/3/)\\n\\n### Search\\n\\nArrays are just lists of entries. Computers can only look at one entry at a time, so search algorithms are needed to look up specific entries.\\n\\n### Big *O*\\n\\nMost search algorithms try to achieve the same thing. The main difference is the running time. This is not exactly in seconds but as the complexity of the algorithm.\\n\\nTo do that one uses the big *O* notation, which describes how much time the algorithm takes approximately dependent on the size of the problem. The most common running times are:\\n- \\\\\\\\(O(n^2)\\\\\\\\)\\n- \\\\\\\\(O(n \\\\log n)\\\\\\\\)\\n- \\\\\\\\(O(n)\\\\\\\\)\\n- \\\\\\\\(O(\\\\log n)\\\\\\\\)\\n- \\\\\\\\(O(1)\\\\\\\\)\\n\\nThe \\\\\\\\(O\\\\\\\\) describes the upper bound of time steps an algorithm takes. The lower bound is described by \\\\\\\\(\\\\Omega\\\\\\\\), and if the two are the same one uses \\\\\\\\(\\\\Theta\\\\\\\\).\\n\\n### Different search algorithms\\n\\n[Here.](search)\\n\\n### Different sorting algorithms\\n\\n[Some Sort Algorithms.](sort)\\n\\n### Recursion\\n\\nRecursion can be helpful to express logic, for example binary search. One needs to be careful when defining the breaking condition, so not too much memory is used by going too deep.\\n\\n## [Lecture 4](https://cs50.harvard.edu/college/2022/spring/notes/4/)\\n\\nPointers are variables which store memory addresses where the values of other variables might be stored. It\'s important to know the difference, so not to copy the address and think one copied the value of the variable.  \\nThe Syntax for arrays just uses the address of the first element and adds the indices of the successive elements to that address. Same is happening with strings. Strings are just one pointer to the first character. The computer looks at the successive addresses and stops at the element `\\\\0`.  \\nIt\'s important to know that when accessing uninitialized memory one can see values that have been saved by previous programs at that address. This can be dangerous, if there are passwords saved for example.  \\nOne can check memory errors with valgrind on the command line.  \\nAll this is important if one wants to make the program as efficient as possible and debug deep down. But for high level languages like python this is not as important as python mostly handles this for you, with less efficiency.\\n\\n## [Lecture 5](https://cs50.harvard.edu/college/2022/spring/notes/5/)\\n\\n### Linked lists\\n\\nLinked lists are list where the elements are not stored behind each other in memory but at separate places. After the first value one needs to store a pointer to the next value, and so on.  \\nIf one wants to add a element to a normal array and the memory slot after the originally last element is already full, we have an issue. We can either copy the array to a new location in memory with enough space, which requires some runtime, or we use a linked list where adding a new element is trivial, as the element after the last element is always reserved for a pointer to a potential new element.  \\nSo if we have a constant length list, use a normal array, as the linked list would require more memory. If we might change the length of the list, use a linked list, as the overhead is less than the potential cost of copying a normal array.\\n\\n### Trees\\n\\nTrees are just defined by nodes. A node is a data structure which has one value and can have multiple pointers to child nodes.\\n\\n### Other data structures\\n\\nThere are several other data structures like queues (first-in-first-out), stacks (last-in-first-out) and dictionaries.\\n\\n## [Lecture 6](https://cs50.harvard.edu/college/2022/spring/notes/6/)\\n\\n### Learning a new programming language\\n\\nMost programming languages are pretty similar. All of them have conditions, operators, data structures and other things. Differences are often just syntax or bigger things like how they handle scopes of variables and types. All in all, if you have mastered one language it is pretty easy to learn another language up to a decent level.\\n\\n## [Lecture 7](https://cs50.harvard.edu/college/2022/spring/notes/7/)\\n\\n### Data processing\\n\\nWhen downloading datasets or even collecting them yourself, most of them are not cleaned. Which means, there might be typos, different names for the same thing, columns which should be multiple columns and much more ugliness. Python is well equipped to clean data, especially with the help of regular expressions. However for quick fixes or searches a database language like sqlite is probably easier. To combine both, one can execute sql commands from within python with the sqlite library.  \\nWhen working with databases the most important thing is to escape user input to avoid injection attacks. When working with multiple servers and multiple users one should lock data that is currently changed by one server. Otherwise a second server might change the same data at the same time and one change gets lost or even worse unintended stuff happens.\\n\\n## [Lecture 8](https://cs50.harvard.edu/college/2022/spring/notes/8/)\\n\\n### The internet\\n\\n#### IP\\n\\nThe internet is basically just a big web of all the routers and in extension the computers/devices and servers of a lot of people in the world. One can send information to any other point in that web. To achieve that, one needs the internet protocol (IP) to tell the routers where to send the information.  \\n\\n#### TPC/UDP\\n\\nTPC is another protocol that helps with sending information to different programs of one IP address. It also allows sending large chunks of data in multiple parts. If the user has a bad connection certain parts can be sent again instead of all the parts. UDP is a protocol that allows sending large amounts of data, but it doesn\'t grantee delivery. This is useful for calls or other real time applications as one doesn\'t want to wait for new data, just to resend earlier data to get the perfect result.  \\n\\n#### DNS\\n\\nWhen you type in a address in your web browser the computer and then your router somehow needs to know what IP address corresponds to the web address. This is done with DNS servers, which have huge lists which save these correspondences. So your router always first contacts a DNS server and gets a IP address back, which then can be used to contact the correct server to get the information one wants.\\n\\n### Clientside\\n\\n#### HTTP\\n\\nBrowsers use Hypertext Transfer Protocol (HTTP) to interface with TPC/IP packets. HTTPS ensures the packets that arrive at the browser are encrypted.\\n\\n#### URL\\n\\nA web address like <https://www.google.com> is also called a URL.\\n\\n#### GET/POST\\n\\nGET and POST requests can be used by browsers to request content from servers.  \\nYou can use `curl` on the command line to check the headers of the responses of servers to GET requests.  \\n```zsh\\ncurl -I -X GET https://www.harvard.edu/\\n```\\nThe status codes one gets back can then be interpreted and used to modify the request to get the correct response.\\n\\n#### HTML\\n\\nHypertext Markup Language is used to tell the browser what and how to display information. It is however not a programming language.\\n\\n#### CSS\\n\\nTo style HTML one can use Cascading Style Sheets (CSS) which isn\'t a programming language either.\\n\\n#### JavaScript\\n\\nTo change elements and styling one can use JavaScript, which is a programming language. It will be executed on the device of the user.\\n\\n## [Lecture 9](https://cs50.harvard.edu/college/2022/spring/notes/9/)\\n\\n### Web server programming\\n\\nA framework like flask or django can be used to program a server with python to send responses to users. So when the user types in a certain URL or clicks on a link, the server sends data in terms of a HTML page, CSS and JavaScript back. This data can be dynamically generated with the full power of python. The python code then communicates on the server with a database, sometimes on another server.  \\nThis enables accounts and other things where the website needs to remember stuff about the user. Often times, for example for autocomplete it is helpful to use a mix of JavaScript and serverside code to accelerate the results, as responses from the server take some time compared to calculations on device."},{"id":"/daily","metadata":{"permalink":"/blog/daily","source":"@site/blog/daily.md","title":"Daily ToDos","description":"- program autotuner for hyperparameter optimization","date":"2023-09-23T15:55:21.000Z","formattedDate":"September 23, 2023","tags":[],"readingTime":0.075,"hasTruncateMarker":false,"authors":[],"frontMatter":{"title":"Daily ToDos","layout":"base"},"prevItem":{"title":"CS50","permalink":"/blog/cs50"},"nextItem":{"title":"Data Preparation and Feature Engineering","permalink":"/blog/data_preparation"}},"content":"- program autotuner for hyperparameter optimization\\n\\n- get basic blocks for good project structure going"},{"id":"/data_preparation","metadata":{"permalink":"/blog/data_preparation","source":"@site/blog/data_preparation.md","title":"Data Preparation and Feature Engineering","description":"SQL is probably most useful, when it just comes to data manipulation and query. Excel is easier because it is more \\"what you see is what you get\\" due to the UI. If you need to go beyond data manipulation into machine learning python is probably the best.","date":"2023-09-23T15:55:21.000Z","formattedDate":"September 23, 2023","tags":[],"readingTime":1.4,"hasTruncateMarker":false,"authors":[],"frontMatter":{"layout":"base","title":"Data Preparation and Feature Engineering"},"prevItem":{"title":"Daily ToDos","permalink":"/blog/daily"},"nextItem":{"title":"Training Guide","permalink":"/blog/deep_learning"}},"content":"SQL is probably most useful, when it just comes to data manipulation and query. Excel is easier because it is more \\"what you see is what you get\\" due to the UI. If you need to go beyond data manipulation into machine learning python is probably the best.  \\nTo learn SQL and use python for establishing a pipeline for machine learning, the best thing might be to use python to automate SQL commands. For quick stuff google sheets is probably good to learn.\\n\\n# Overview\\n\\nMachine Learning generally tries to recognize patterns in data to then generate new data points.\\nTo achieve that, one needs to generate and transform a dataset to feed into the algorithms.\\n\\nMainly just notes taken from [Google](https://developers.google.com/machine-learning/data-prep).\\n\\n# Dataset Generation\\n\\n# Dataset Transformation\\n\\n## When to transform\\n\\n### Prior to training\\n\\n#### Pros\\n\\n- computation only performed once\\n\\n#### Cons\\n\\n- Transformations need to be reproduced at prediction time. New data can be unpredictable.\\n- need to rerun dataset generation when changing transformations, which may lead to slow iterations. Not an issue with a small dataset.\\n\\n### Within the model\\n\\n#### Pros\\n\\n- can always use the same data, as happen in the model.\\n- when changing transformations the same data is still used, which leads to fast iterations.\\n\\n#### Cons\\n\\n- transformations can increase latency, this is the case with transformations at prediction time as well.\\n\\n## Visualizations\\n\\nAlways look at graphs or other visualizations of your dataset, before and after transformations to detect errors or irregularities.\\n\\n## Normalization\\n\\nWhen having features with highly different ranges of numeric values it is recommended to perform normalization.\\nGradient decent can have issues and slowly converge otherwise."},{"id":"/deep_learning","metadata":{"permalink":"/blog/deep_learning","source":"@site/blog/deep_learning.md","title":"Training Guide","description":"Expand on this.","date":"2023-09-23T15:55:21.000Z","formattedDate":"September 23, 2023","tags":[],"readingTime":0.015,"hasTruncateMarker":false,"authors":[],"frontMatter":{"title":"Training Guide","layout":"base"},"prevItem":{"title":"Data Preparation and Feature Engineering","permalink":"/blog/data_preparation"},"nextItem":{"title":"Electric vehicles","permalink":"/blog/electric_vehicles"}},"content":"Expand on [this](http://karpathy.github.io/2019/04/25/recipe/)."},{"id":"/electric_vehicles","metadata":{"permalink":"/blog/electric_vehicles","source":"@site/blog/electric_vehicles.md","title":"Electric vehicles","description":"Ideally we would all be using public transport, bicyles and our legs. But humans want for various reasons personal vehicles. Currently we mainly use internal combustion engines (ICE) cars. Due to their emission of co2 and resulting human made climate change we need other solutions in the long term. Electric vehicles are the prime candidate for that position.","date":"2023-09-23T15:55:21.000Z","formattedDate":"September 23, 2023","tags":[],"readingTime":0.95,"hasTruncateMarker":false,"authors":[],"frontMatter":{"title":"Electric vehicles","layout":"base"},"prevItem":{"title":"Training Guide","permalink":"/blog/deep_learning"},"nextItem":{"title":"Investing","permalink":"/blog/etf_investing"}},"content":"Ideally we would all be using public transport, bicyles and our legs. But humans want for various reasons personal vehicles. Currently we mainly use internal combustion engines (ICE) cars. Due to their emission of co2 and resulting human made climate change we need other solutions in the long term. Electric vehicles are the prime candidate for that position.\\n\\nThere are other possibilities like hydrogen fuel cell or biofuel engines. But these \\"solutions\\" might only be feasible in the future. But we need a solution right now and with battery electric vehicles (BEVs) we have everthing we need. The only thing BEVs lack behind other options is the range and the charging speed. But is not a concern for most people in everyday life because the can charge at home over night and almost never need to drive the maximum range in their daily life.\\n\\nThe other concern many people have is that BEVs are actually not more \\"green\\" than ICEs due to the high energy use when producing the battery and that buying a tesla is not environmentally friendly. There is a more difficult and an easy argument against this."},{"id":"/etf_investing","metadata":{"permalink":"/blog/etf_investing","source":"@site/blog/etf_investing.md","title":"Investing","description":"!!! Es wurden nur 1-2 verschiedene Quellen angegeben, allerdings sind die meisten Aussagen nicht wirklich kontrovers. Die meisten Dinge lassen sich schnell auf Investopedia oder anderen Seiten finden. Ich war nur zu faul alles anzugeben.","date":"2023-09-23T15:55:21.000Z","formattedDate":"September 23, 2023","tags":[],"readingTime":3.8,"hasTruncateMarker":false,"authors":[],"frontMatter":{"title":"Investing","layout":"base"},"prevItem":{"title":"Electric vehicles","permalink":"/blog/electric_vehicles"},"nextItem":{"title":"Fake news","permalink":"/blog/fakenews"}},"content":"**!!! Es wurden nur 1-2 verschiedene Quellen angegeben, allerdings sind die meisten Aussagen nicht wirklich kontrovers. Die meisten Dinge lassen sich schnell auf Investopedia oder anderen Seiten finden. Ich war nur zu faul alles anzugeben.**\\n\\n## Timeframe\\n\\n~15 years\\n\\n## ETF\\n\\nETFs sind wie Fonds, kleine Anteile von Unternehmen in \\"Packet\\". Kann dadurch \xfcber verschiedene Branchen und \xfcber die ganze Welt geographisch gestreut werden. Daraus folgt, dass nicht mehr in bestimmte Unternehmen, sondern in den **gesamten Markt** investiert wird.\\n\\nDer Unterschied von ETFs im Vergleich zu Fonds ist das Management. Fonds werden von Angestellten von Banken gemanaged und **aktiv Aktien hinzugef\xfcgt oder verkauft**. Dies ist mit **Personalkosten** verbunden. ETFs werden **automatisch gemanaged** und versuchen so genau wie m\xf6glich einem **Index zu folgen**. Diese Indizes werden auf Basis von bestimmten Regeln aufgestellt. Mcsi world setzt sich beispielsweise aus den top (70%) Unternehmen mit den h\xf6chsten Marktkapitalisierung aus bestimmten L\xe4ndern zusammen. Die Kostenunterschiede zwischen ETFs und aktiven Fonds betr\xe4gt meist **~1%**.\\n\\nDiese Differenz muss durch die Experten der Banken, welche diese Fonds managen, **zus\xe4tzlich zu der Rendite des ETFs** erreicht werden, sodass der Fond ein besseres Investment als der ETF ist. Dies wird meist nicht erreicht bzw. ist wieder ein Gl\xfccksspiel in sich selbst, da der \\"richtige\\" Fond herausgesucht werden muss und oft sind diese nicht wirklich transparent. Zudem ist es so gut wie **unm\xf6glich den Markt zu verstehen** und falls Experten dies t\xe4ten, w\xfcrden sie vermutlich keine Fonds managen sondern selbst traden und nicht mehr arbeiten m\xfcssen.\\n\\nDie Annahme, dass der **Markt immer weiter steigt**, ist warscheinlich korrekt. Menschen wollen schon immer mehr Dinge und ein \\"besseres\\" Leben. Die Industriel\xe4nder sind vielen Teilen der Welt vorraus. Auch wenn die Industriel\xe4nder sich entscheiden sollten nicht mehr so viel zu produzieren (evtl. auf Grund des Klimawandels) wird vermutlich immer noch der Rest der Welt nachziehen und G\xfcter ben\xf6tigen. Zudem wird dies vermutlich nicht in den n\xe4chsten ~30 Jahren passieren, wenn \xfcberhaupt.\\n\\n[Mcsi world \xfcber 15 jahre](https://ystat.org/) (seite down &rarr; [\xe4hnlich](https://backtest.curvo.eu/portfolio/msci-world--NoIgsgygwgkgBAdQPYCcA2ATEAaYoAyAqgIwDsAHMQKwAsxZAnDsQLptA)) median rendite 8.78%, **schlechteste 3.16% pro jahr** (abh\xe4ngig davon wann gekauft/verkauft wird). Das wichtigste ist, dass die varianz mit l\xe4ngeren Investmentperioden sinkt und nach 10-15 Jahren die Chance f\xfcr positive Rendite \xfcber 90% liegt und nach 20 Jahren gar bei 100% (auf der [Seite](https://backtest.curvo.eu/portfolio/msci-world--NoIgsgygwgkgBAdQPYCcA2ATEAaYoAyAqgIwDsAHMQKwAsxZAnDsQLptA) zu Minimum investment horizon und Compute clicken). Nat\xfcrlich sind dies historische Daten und garantieren nichts f\xfcr die Zukunft, jedoch sind sie trotzdem gute Anhaltspunkte, da der gesamte Markt sich in Zukunft vermutlich auf lange Sicht \xe4hnlich verhalten wird.\\n\\n## Broker\\n\\n- Hohe Sicherheit (haben eigentlich alle hier in Deutschland + deutsche Einlagensicherung bis 100.000\u20ac)\\n- keine Verwahrungsgeb\xfcren (ist bei den meisten auch so)\\n- geringe Kosten f\xfcr einmaligen Kauf (gut wenn pauschal, schlecht wenn %)\\n\\nEs ist schwer Beispiele zu nennen, da die Konditionen der Broker sich andauernd \xe4ndern. Generell bieten jedoch die \\"alten\\" Banken schlechtere Konditionen. Ein weiterer wichtiger Faktor ist oft, ob die Broker eine gute App und Website anbieten, da viele Banken noch sehr hinterher sind. Am besten kurz immer YouTube Videos angucken, um die Apps in Aktion zu sehen. Man k\xf6nnte allerdings auch argumentieren, dass es besser ist keine oder keine gute App zu haben, da dies bei vielen Leuten zu Impuls K\xe4ufen oder Verk\xe4ufen f\xfchren kann, da es so einfach ist. \\n\\n## Nachhaltigkeit\\n\\n- **ESG**: Ziel ist immer noch Performance. Es werden Unternehmen ausgeschlossen die durch bestimmte umweltsch\xe4dlichen, sozialen oder ihr Regime negativ auffallen, und dadurch auch eventuell schlechtere Performance erreichen (so weit ich wei\xdf wurde aber noch keine klare Korrelation mit schlechterer Performance festgestellt).\\n- **SRI**: strenger als ESG, suchen aktiv Unternehmen nach ethischen Richtlinien herraus, verwenden allerdings auch teilweise das ESG-Rating zur auswahl, nur die Grenze ist strenger.\\n\\nGute Videos daf\xfcr: [[1]](https://www.youtube.com/watch?v=6kIzjD_seLI)[[2]](https://www.youtube.com/watch?v=VeBHRURmh1U) oder in [Text Form](https://www.finanzfluss.de/geldanlage/nachhaltige-etfs/).\\n\\nOder einfach [Investopedia](https://www.investopedia.com/financial-advisor/esg-sri-impact-investing-explaining-difference-clients/).\\n\\n\\n## 70/30\\n\\nMit dem MSCI World werden nur die Industriel\xe4nder abgedeckt. Um noch breiter zu diversifizieren ist es sinnvoll ca. 30% des Portfolios in beispielsweise den MSCI World Emerging Markets (EM), welcher viele Schwellenl\xe4nder noch mit abdeckt. Alternativ ist es noch m\xf6glich etwas Europa dazuzunehmen, wenn die \xdcbergewichtung der USA im MSCI World nicht gef\xe4llt.\\n\\n[Hier](https://www.finanzfluss.de/etf-handbuch/etf-portfolio/) noch ein paar andere Porfolioarten zum Vergleich.\\n\\n## M\xf6gliche ETFs\\n\\n**MSCI World SRI (70%):**\\n\\n- Amundi Index MSCI World SRI UCITS ETF DR (WKN: A2JSDA ISIN: LU1861134382)\\n\\n**MSCI World Emerging Markets SRI (30%):**\\n\\n- iShares MSCI EM SRI UCITS ETF (WKN: A2AFCZ ISIN: IE00BYVJRP78)\\n- Amundi Index MSCI Emerging Markets SRI UCITS DR ETF (C) (WKN: A2JSDD ISIN: LU1861138961)\\n\\nZum finden ist [justETF](https://justetf.com/en/find-etf.html) gut. Einfach einen Index ausw\xe4hlen und nach Kriterien filtern. Hier noch eine [Seite](https://www.finanzfluss.de/etf-handbuch/etf-auswahl-kriterien/) f\xfcr Tips auf welche Dinge bei der Auswahl zu achten ist."},{"id":"/fakenews","metadata":{"permalink":"/blog/fakenews","source":"@site/blog/fakenews.md","title":"Fake news","description":"Google bias","date":"2023-09-23T15:55:21.000Z","formattedDate":"September 23, 2023","tags":[],"readingTime":10.46,"hasTruncateMarker":false,"authors":[],"frontMatter":{"title":"Fake news","layout":"base"},"prevItem":{"title":"Investing","permalink":"/blog/etf_investing"},"nextItem":{"title":"Habits","permalink":"/blog/habits"}},"content":"## Google bias\\n\\n### The Enduring Anti-Black Racism of Google Search\\n\\nlink: https://onezero.medium.com/the-enduring-anti-black-racism-of-google-search-d024924bff77\\n\\n#### Bad article\\n\\nA search engines job should be to get users the information they want. It feels like the baseline for zero bias is what the internet offers. So when the whole internet is nine images of an apple and one image of a banana, it would be good to expect an apple more often when searching for \\"fruit\\".\\n\\nSo when there are the tags for \\"black girls\\" are overwhelmingly found on porn sites it should be to no surprise that google shows those when searching for \\"black girls\\".\\n\\nIt feels like, if google would not intervene in the \\"societal\\" distribution of the search results, we would have more racist search results, as one can see at the exact example in the article. So to blame google instead of the culture of the people is wrong. So google actually does bias the results, however one could argue that that\'s a good thing. The author shouldn\'t blame google for the few times reality was shining through, but thank google for adjusting some bad baselines in society.\\n\\nIt might be helpful to get some diversification in the workplace to help these things, however those need not necessarily be engineers, as the manual adjustments shouldn\'t have anything to do with engineering, rather with social studies or ethics.\\n\\nThe whole thing is hard to evaluate since we don\'t exactly know how google selects the search results, however the alternatives are hard to imagine. Is the implication of the article that google engineers went ahead and weighted porn websites higher when searching for \\"black girls\\" instead of \\"white girls\\"? What would be the motive behind that?\\n\\n#### Some weird quotes\\n\\n> Pornography is a specific type of representation that denotes male power, female powerlessness, and sexual violence.\\n\\nThis feels wrong.\\n\\n> Porn on the internet is an expansion of neoliberal capitalist interests. The web itself has opened up new centers of profit and pushed the boundaries of consumption. Never before have there been so many points for the transmission and consumption of these representations of Black women\u2019s bodies, largely trafficked outside the control and benefit of Black women and girls themselves.\\n\\n- Why is an expansion of capitalist interests bad?\\n- Isn\'t that good for a lot of people?\\n- What does neoliberalism have to do with it? \\n- The assumption that the consumption is \\"largely\\" outside the benefit of black woman needs to be justified.\\n    - black woman that do porn do benefit? If they are exploited there is another question. (more fame, money, like music labels)\\n    - why only for black woman? And what about men in porn? (earn way less than woman)\\n\\n### Gunn and Lynch Googling (2019)\\n\\nChapter 4, page 41-51\\n\\n#### Risks of googling\\n\\n- anonymity, no accountability of face-to-face information. Not a google issue, internet issue.\\n- no way to make sure that information is good, same issue in real life, but internet gives broader view quickly. One needs to check multiple sources, integrate in world view and check for inconsistencies.\\n- reductionism\\n    - reductionism: trust is earned not assumed\\n    - anti-reductionism: just trust others, assuming they have similar thinking faculties\\n- google searches lead to most wanted results, assumed to be right, because many others found it to be right\\n- trust if author is trusted, problematic, but not unique to internet\\n    - collective of authors (wikis)\\n    - some are automated (currency exchange)\\n\\n#### selecting sources\\n- more reliable information is shared more, higher in ranking, good\\n- sometimes information of influencers does have popularity-because-popular, bad\\n- there are often experts on both sides, use institutional markers\\n- use of likes, upvotes, titles (must not necessarily be a good marker)\\n- advertising can be misleading\\n- Wikipedia can be good as everything needs source from expert, but can be outdated due to lag of checkups\\n- not all people are able to select \\"good\\" sources, most just accept everything google gives them first.\\n\\n#### Google in Brain\\n- extend brain with chip, access fast amounts of information at speed of thought\\n- accelerates effects/issues above\\n\\n## Epistemic Agency\\n\\n### Tugend\\n\\nVerantwortung\\nAnonymity\\n\\n## On trusting Wikipedia\\n- generally trusted\\n- not always correct\\n\\n\\n## Wikipedia and the epistemology of testimony (by deborah perron tollefsen)\\n\\n### Introduction\\n\\n- studies mainly focus on individual testimony\\n- group testimony can\'t always be understood as just a summation of individual testimony\\n- the group itself testifies\\n- example Wikipedia\\n\\n### Questions\\n\\n- Is Wikipedia a source of testimony?\\n- What is the nature of that source?\\n    - the individuals that make entries\\n    - a subset of individuals\\n    - the entity Wikipedia itself\\n- How can we asses the trustworthiness of Wikipedia as such an unusual epistemic source?\\n\\n### Are the statements on Wikipedia testimony?\\n\\n#### define testimony\\n- conservative (Coady 1992)\\n    - speakers intention to present evidence on a specific matter in the interest of the audience\\n- liberal (E. Fricker 1995, Sosa 1991)\\n    - \\"tellings in general\\" with no restriction on the domain\\n- Jennifer Lackey (2006)\\n    - \\"S testifies that p by making an act of communication a if and only if (in part) in virtue of a\u2019s communicable content, (1) S reasonably intends to convey the information that p, or (2) a is reasonably taken as conveying the information that p.\\"\\n    - so it is a testimony if the speaker intends to convey information or if the audience takes it as such\\n\\n#### Wikipedia as testimony\\n\\nAll would obviously include Wikipedia as testimony.\\n\\nAssumption: People are trolling, writing false information for fun.\\n\\nSome definitions of testimony might be broken. Lackey\'s definition would still include Wikipedia as testimony, as people who read Wikipedia still assume it to be testimony.\\n\\nWray: not all entries are testimony, some are jokes, so nothing is testimony.\\n\\nDoesn\'t mean nothing is testimony.\\n\\nTestimony is not only what one believes, otherwise there would be no false testimony.\\n\\nMoran(2006), Assurance view: Testimony comes with assurance that statement is true. Testifiers have responsibility to be truthful. They are aware that they might be questioned and need to explain themselves if the statement is false.\\n\\nThe same is true on Wikipedia. People can change information, but they know that they can then be called to question by other people that can discuss these changes and change them again.\\n\\nEven if a troll is sometimes hard to track down and question, the information still is taken to come with assurances.\\n\\nSo none of the definitions of testimony would exclude Wikipedia as testimony.\\n\\n### Group testimony\\n\\nNew Question: Is the source the person that writes the entry or the entity Wikipedia?\\n\\nWhen group decides something, it doesn\'t necessarily follow that all or most of the group, would testify the similarly.\\n\\n**Example:**\\n\\nNAS needed to make statement on long term genetic hazards of radiation exposure. It was a difficult decision, but needed to be made to protect the public from other, more harmful misinformation.  Some scientists even refused to sign it, because they thought it was indeterminable. In the end they all signed.\\n\\nFor a group G, speaker S, and utterance x, G utters x if and only if:\\n1. There exists a group (G), this group has an illocutionary intention, and x conveys that illocutionary intention.\\n2. S believes that he or she knows the illocutionary intention of G and that x conveys this illocutionary intention.\\n3. G does not object to S uttering x on its behalf and if G intends for any specific individual(s) to utter x, it intends for S to utter x. S believes that he or she knows this.\\n4. 2 and 3 are the reasons S utters x.\\n\\nNeed to add 5th condition.\\n\\n5. S utters G in the proper social and normative context.\\n\\nThis is important, as the NAS group would probably not have signed the statements, if it wasn\'t necessary to keep public trust and safety.\\n\\nSo group testimony (group speech act with conveyed information):\\n\\nGroup G testifies that p by making an act of communication a if and only if:\\n1. (in part) in virtue of a\u2019s communicable content G reasonably intends to convey the information that p.\\n2. The information that p is conveyed by either (i) a spokesperson S or (ii) a written document.\\n3. If (i), G does not object to S\u2019s uttering p on its behalf and if G intends for any specific individual(s) to utter p, it intends for S to utter p and S believes that he or she knows this.\\n4. If (i), S utters p for the reasons in 3.\\n5. If (ii), G does not object to the way in which p is conveyed in writing.\\n6. G conveys the information that p in the right social and normative context.\\n7. In conveying the information that p in the right social and normative context, G is taken to have given its assurance that p is true.\\n\\n### Wikipedia entries as group testimony\\n\\nTraits shared by groups (research teams, governments or corporations)\\n- share certain goals\\n    - clear goals on Wikipedia: natural, balanced, verifiable knowledge to all for free\\n    - contributors have largely those goals, would be hard to explain otherwise\\n- are aware that they share these goals\\n    - \\"Wikipedia community\\", \\"Wikipedians\\" are names used, Wikipedia conferences exist\\n    - there are pages on Wikipedia that explain itself, so its self reflective\\n- group decision making process with specific rules\\n- group members have special rights and obligations\\n\\nArticles are testimony of Wikipedia once they have been discussed at length and have been approved by the community, they become featured or good articles.\\n\\n\\nUntil then, they are either individual or group testimony.\\n\\nThe trustworthiness of Wikipedia needs to be monitored in those early stages, while \\"steadying ones mind\\", almost like a child.\\n\\n### Trustworthiness of Wikipedia\\n\\nAnti-reductionism: Trust others, assuming they have similar thinking faculties. (normal conversation)\\nReductionism: Trust, if there are positive reasons, that the other person is sincere/reliable.\\n\\n#### Anti-reductionism\\nNormal conversation with one person is on topics with not expertise, so anti-reductionism is fine. Generally groups have some kind of specific expertise (governmental, scientific, legal). With Wikipedia its different, because it speaks on a wide range of interests (more like a person on the street).\\n\\nHowever the standard trust assumption of anti-reductionism may fail with Wikipedia, if it\'s treated as a child/unstable.\\n\\n#### Reductionism\\n\\n##### Scrutinize the speaker/Wikipedia\\n\\n- Sum of individuals:\\n    - check if some or all of the contributors are reliable\\n    - often short track record of contributors, hard to evaluate\\n    - mature articles could be closer to the truth than the individual entries of the contributors through the process of discussion and approval\\n    - might tell us nothing about the trustworthiness of Wikipedia\\n- Systematic cues:\\n    - Programs can figure out anomalies (quick changes without discussion after long stable period, information that doesn\'t fit into the style of the article)\\n    - quick correction of spelling/grammatical errors might hide red flags for the content of the entry from the reader; one can still check the history (most probably wont)\\n    - trust the system not the individuals\\n\\n##### Scrutinize the content\\n\\nVerify with own background knowledge. Integrate in world view and check for inconsistencies.\\nA UFO landed on the school roof (unlikely because of prior believe)\\nTrust the process and the reports, not the individuals.\\nThere are incentives for groups to tell the truth(scientific groups, some corporations)\\n\\nIf group testimony is wildly at odds with your own knowledge, one has no reason to trust it.\\n\\n**Wikipedia**:\\n- incentives are in the structure of the system\\n- entries will be checked against background knowledge\\n- by challenging Wikipedia, its reliability increases through new policies and procedures\\n\\n### Conclusion\\n\\n- Wikipedia involves a mix of individual, group and Wikipedia testimony\\n- Can\'t trust Wikipedia by default, yet (still a child)\\n- Will get better once it matures, and doesn\'t need to be constantly monitored\\n\\n### Discussion Questions\\n\\n\\n## Fake News and Partisan Epistemology\\n\\n\\n## Context Collapse\\n\\n## Hopeful Trust\\n\\nPendulum swung too far:\\n- Tweets with misinformation are taken as truth because of labels of person (trans, black); Trust gets abused by speaker. It is assumed people trust the person just because of the label. Examples dispropotionally damage trust in thruthful speakers.\\n\\t- trans person claiming periods https://twitter.com/poisonaivy69/status/1507362480158355508\\n\\t- jakob blake misinfo\\n\\n- vulnerability invites trust, but only sometimes. On social media, one needs to take the average to see effect\\n\\t- trump voters meat trans poeple in real life"},{"id":"/habits","metadata":{"permalink":"/blog/habits","source":"@site/blog/habits.md","title":"Habits","description":"Don\'t multitask","date":"2023-09-23T15:55:21.000Z","formattedDate":"September 23, 2023","tags":[],"readingTime":3.805,"hasTruncateMarker":false,"authors":[],"frontMatter":{"title":"Habits","layout":"base"},"prevItem":{"title":"Fake news","permalink":"/blog/fakenews"},"nextItem":{"title":"Human Robot Interaction","permalink":"/blog/hri"}},"content":"## Don\'t multitask\\n\\nIt just doesn\'t work, you think it works, but it doesn\'t. You\'re just switching between tasks, and you\'re not doing any of them well. Or you are doing one with 80% of your brain and the other 20%, so the one with 20% isn\'t even enjoyed, so why not do it with 100% of your brain in your free time.\\n\\n## Social media/ entertainment\\n\\nOnly watch them while eating or in free time. Then you can watch the highlights of the day, and not needing to search for cool stuff while you should be working or doing other things.\\n\\n## Sleep\\n\\nKeep sleep schedule, wake up early, try 8h.\\n\\n## Exercise\\n\\nMix running and at home exercise, depending on weather and state of mind. Don\'t miss two days in a row. Its easy to lose the habit then.\\n\\n## Eat healthy\\n\\nJust count your calories, and eat filling foods. Mix it up, change some vegetables, proteins and spices in the recipes, mix up rice with noodles or lentils.\\n\\n## Work\\n\\nEliminate distractions. Block websites like YouTube, Twitch, Twitter, etc. Work for selected periods of time, but focused.\\n\\n## Do your bed\\n\\nYeah, sounds like the meme daddy Peterson tells you, but it helps, its a small task that\'s easy to accomplish, and it makes you feel good. It\'s a good habit to start with.\\n\\n## Shower\\n\\nJust shower early in morning, makes you feel fresh and ready for the day. And wear clothes that you would wear in public or work. Makes you feel ready.\\n\\n## Walks\\n\\nTake a walk without any distractions. No phone, just enjoy the nature. It\'s good for your mind and body. It may sound stupid, but it will make you feel better.\\n\\n## ToDo list\\n\\nDon\'t put too many tasks on there, and make them as small as possible. That way, you can actually achieve them, and don\'t feel bad because you only managed to complete half of them by the end of the day.\\n\\n## Free time\\n\\nYou need some dedicated time to do whatever you want. If not, it will creep into the time you should be working.\\n\\nGood time to socialize. Meeting friends helps.\\n\\n# Default Schedule\\n\\n| Time        | Task           |\\n| ------------- |:-------------:|\\n| 7:00      | Wake up, Shower, Get ready |\\n| 7:30      | Go for a walk      |\\n| 7:50 | Breakfast      |\\n| 8:15 | Schedule my day      |\\n| 8:30 | Work      |\\n| 12:00 | Do exercise      |\\n| 12:30 | Lunch      |\\n| 13:30 | Work      |\\n| 19:00 | Dinner      |\\n| 19:30 | Do whatever I want      |\\n| 22:30 | Sleep      |\\n\\n# Alternative Schedule\\n\\n| Time        | Task           |\\n| ------------- |:-------------:|\\n| 7:00      | Wake up, Shower, Get ready |\\n| 7:30      | Go for a walk      |\\n| 7:50 | Breakfast      |\\n| 8:15 | Schedule my day      |\\n| 8:30 | Work      |\\n| 12:00 | Do exercise      |\\n| 12:30 | Lunch      |\\n| 13:30 | Work      |\\n| 17:00 | Do whatever I want      |\\n| 22:30 | Sleep      |\\n\\n\\n# Rules\\n\\n1. Only use social media during food slots\\n2. Socialize only after 16:00, if work is done.\\n3. Can take two days off each week, if i feel like it.\\n4. If I feel healthy and motivated, I can follow the routine every single day, without off days.\\n\\n# Food Plan (Weekly):\\n\\n| Day        | Meal |\\n| ------------- |:-------------:|\\n| Monday | Tofu, zucchini, bell pepper, soy sauce, ginger stir fry with white rice|\\n| Tuesday | Lentil soup with a side of whole grain crackers/bread|\\n| Wednesday | Quinoa bowl with roasted mushrooms and brokkoli with lemon juice|\\n| Thursday | Tofu, zucchini, bell pepper, soy sauce, ginger stir fry with white rice|\\n| Friday | Spinach and tomato omelet with whole grain toast|\\n| Saturday | Wrap with hummus, roasted eggplant and arugula|\\n| Sunday | Tofu, zucchini, bell pepper, soy sauce, ginger stir fry with white rice|\\n\\nEvery day: Spices (pepper, salt, thyme, rosemary, garlic powder)\\n\\n\\n# Shopping List (Wednesday):\\n\\n## Fresh:\\n\\n### Vegetables/Fruits:\\n- 3x zucchini\\n- 3x bell pepper\\n- 3x mushrooms\\n- 1x eggplant\\n- tomatoes\\n- brokkoli\\n- fresh spinach\\n- arugula\\n- 3x ginger\\n\\n### Other:\\n- 3x tofu\\n- hummus\\n- 4x eggs\\n- wraps\\n- cheese\\n\\n## Bulk:\\n- soy sauce\\n- quinoa\\n- lentils\\n- white rice\\n- whole grain crackers/bread\\n- hummus\\n- lemon juice (oil)\\n- spices (pepper, salt, thyme, rosemary, garlic powder)\\n- vegetable broth powder"},{"id":"/hri","metadata":{"permalink":"/blog/hri","source":"@site/blog/hri.md","title":"Human Robot Interaction","description":"Task","date":"2023-09-23T15:55:21.000Z","formattedDate":"September 23, 2023","tags":[],"readingTime":17.45,"hasTruncateMarker":false,"authors":[],"frontMatter":{"title":"Human Robot Interaction","layout":"base"},"prevItem":{"title":"Habits","permalink":"/blog/habits"},"nextItem":{"title":"Logic","permalink":"/blog/logic"}},"content":"## Task\\nHRI interface comparisons with examples (VR, AR, bio-signal-based)\\n\\n## Comparison VR, AR, Bio-signal-based\\n\\nAdvantage of all of them is that the user can often interact with the robot in a natural way through hand and body gestures. This makes it possible for users without the technical knowledge of controlling the robot traditionally, to control the robot.\\n\\n### Virtual reality(VR)\\nVirtual reality puts a human into a virtual world to interact with a robot. The human can see the robot and the robot can see the human. The human can interact with the robot by using a controller or by using their hands. \\nOne important aspect is ability to get almost instant feedback from the robot motion. This is important for the human to be able to learn how to control the robot.\\nVR headsets can often be uncomfortable to wear for long periods of time. Newer headsets have batteries instead of cable connections, which can be better or worse depending on the use case.\\nVR could technically do the save as AR does, by just recording the world around the human and displaying parts of it in VR. However the technology isn\'t there yet to perfectly display reality, so there is still clearly a difference.\\nCould pre-render the actions given to the robot, before executing them.\\n\\n### Augmented reality(AR)\\nAugmented reality enhances the real world around the human with digital information to better interact with a robot. The human can see the robot and the robot can see the human. The human can interact with the robot by using a controller or by using their hands.\\nOne difference to VR is the ability to also see and better interact with the real world around the human.\\n\\n### Bio-signal-based\\n\\nBio-signal-based devices can be used to control robots. Many different types of bio-signal-based devices exist, such as EEG, EOG, EMG, ECG, ERG, EGG, GSR and EDA.\\n\\n- Electroencephalography (EEG): Measures electrical activity of the brain.\\n- Electrooculography (EOG): Measures electrical activity of the eye.\\n- Electromyography (EMG): Measures electrical activity of the muscles.\\n- Electrocardiography (ECG): Measures electrical activity of the heart.\\n- Electroretinography (ERG): Measures electrical activity of the retina.\\n- Electroglottography (EGG): Measures electrical activity of the vocal cords.\\n- Galvanic skin response (GSR)/Electrodermal activity (EDA): Measures electrical activity of the skin.\\n\\nThese devices can be used to control robots in many different ways. For example, a person can control a robot by thinking about moving it, or by moving their eyes to look at different parts of the robot. Bio-signal-based devices can also be used to control robots by measuring the person\'s heart rate, or by measuring the person\'s sweat levels.\\n\\n### Some abbreviations\\n\\n- ROS: Robot Operating System\\n\\n\\n### General papers\\n- https://link.springer.com/content/pdf/10.1007/s43154-020-00005-6.pdf\\n    - overview of different HRI interfaces\\n\\n- https://graphics.cs.wisc.edu/Papers/2017/LRMG17/roman-vr-2017.pdf\\n    - general paper about VR as a HRI interface\\n\\n- http://ti.rutgers.edu/publications/papers/1999_ieee_tra.pdf\\n    - paper about using VR for HRI\\n    - decent overview of VR\\n\\n- https://robotics.mit.edu/teleoperating-robots-virtual-reality\\n    - MIT article\\n\\n- https://www.allerin.com/blog/ar-vr-and-other-ways-of-controlling-robots\\n    - article about different HRI interfaces\\n    - might be perfect overview\\n\\n- https://www.mdpi.com/1424-8220/21/20/6863\\n    - huge summary/survey of bio-signal-based solutions\\n    - for assistance/rehabilitation\\n\\n- https://arxiv.org/pdf/2203.03254.pdf\\n    - AR summary\\n    - 2022 paper\\n### General comparisons\\n\\n- https://reader.elsevier.com/reader/sd/pii/S2212827120314815?token=674B622691122E381C72A6FD9A55D0F0163342C7E2F3F3785601BAECC912EB05ED29318E11A2834A7D0B9019B9EE27A6&originRegion=eu-west-1&originCreation=20221104125245\\n    - Review of VR/AR solutions for HRI\\n\\n- https://cs.brown.edu/people/er35/publications/SIEDS_2020.pdf\\n    - comparison of different VR approaches\\n    - positional control (waypoint navigation)\\n    - trajectory control (click and drag)\\n\\n### get at least one paper with an example for every interface type (VR, AR, bio-signal-based)\\n\\n#### VR\\n- https://arxiv.org/pdf/1903.10064.pdf\\n    - controlling a swarm of robots with VR\\n    - manipulating the environment in VR, zooming in and out\\n    - placing walls in the environment to block the robots\\n    - highlights intuitiveness of VR\\n    - gestures are intuitive, but need some training\\n    - visual information from the robots gets sent to pc and dynamically rendered in VR\\n    - technically human swarm interaction (HSI)\\n    - summary:\\n    VR is used in \\\\cite to control a swarm of robots. The robots are able to navigate and interact with each other on their own.\\n    The user can use VR to manipulate the environment, zoom in and out, and place walls in the environment to block or guide the robots. Additionally the robots can be picked up and placed in a new location. Leap Motion is used to identify the users motions.\\n    Thus the user can propose future actions or locations in the virtual environment and the robots will try to execute or move to them in the real world.\\n    The authors conducted a usability study with 10 participants between the ages 20 and 35 with an engineering background. Is showed that the controls are intuitive and the test missions are accelerated with the help of human intervention. They note however that some of the gestures, specifically the wall placement and the world resizing, need some training to get used to.\\n\\n\\n- https://h2r.cs.brown.edu/wp-content/uploads/whitney18.pdf\\n- https://cs.brown.edu/people/gdk/pubs/vr_teleop.pdf\\n    - controlling robots over the internet with VR (teleoperation)\\n    - created interface to be used by other researchers\\n    - can be used with consumer-grade headsets\\n    - testing approach: https://cs.brown.edu/people/er35/publications/testing.pdf\\n        - establishes baseline for other research\\n- https://arxiv.org/pdf/1703.01270.pdf\\n    - control of robot arms in VR\\n    - VR Control Room\\n    - highlights collocation capabilities of VR\\n    - pick, place, assembly, manufacturing tasks\\n    - summary:\\n    In \\\\cite a team of researchers use VR to control a robot arm. The robot has two arms and is equipped with a camera at its \\"head\\". The user uses the consumer-grade headset Oculus Rift CV1 and two Razer Hydra hand trackers as controllers.\\n    In VR the robot can then be controlled from a control room, which includes the view of the main camera and two optional views from the two robot arms. So the user feels as if they were in the robots head.\\n    To test the system, the authors made an expert user pick up and assemble a Lego piece. They compared it to an automated algorithm on the same task and were able to show that the human performed perfect, whereas the algorithm showed some weakness on the assembly. The user reported that the cameras in the robot arms helped with the alignment of the pieces.\\n    The teleoperation allows the user to perform actions from a save environment.\\n    The paper highlights the ability of VR to utilize consumer-grade hardware.\\n\\n#### AR\\n- https://www.frontiersin.org/articles/10.3389/frobt.2017.00020/full\\n    - uses tablet\\n    - displays information about the robots motion on the tablet\\n    - one tiltable camera, 1/3 of workspace visible at a time\\n    - uses the tablet to control the robot\\n    - 3 interfaces: control with accelerometer of tablet\\n        - egocentric: user sees the workspace from the robots perspective. Parts of the workspace are not observable due to the lack of field of view and movement of the camera.\\n        - exocentric: user sees the workspace from a fixed position on the ceiling. Vision under the robot arm is blocked, so some objects can\'t be interacted with.\\n        - mobile mixed reality: user sees workspace from tablet in arbitrary position. Can access any location.\\n    - pretrial (place one box somewhere else)  was easier with AR plot over workspace enabled\\n    - mobile performs best\\n    - article about it: https://thenewstack.io/smartphone-app-can-control-robots-augmented-reality/\\n    - summary:\\n    AR can be used to enhance the environment. In \\\\cite the authors compare 3 interfaces. One egocentric, with a tiltable camera on the robots head, one exocentric, with the camera on the ceiling looking down, and the proposed method of using a mobile tablet as the camera. All three approaches use the tablets accelerometer to control the robots arms. The main advantage of the proposed method is, that its cameras field of view can reach all places, unlike the other two.\\n    The users can see an overlay over the workspace on the tablet screen, where the robots maximum range of motion and potential actions can be projected.\\n    When testing the system, users performed better on the pretrial, when having the AR plot enabled. Additionally the mobile reality interface shows better performance than the other two.\\n    The main points to take away, are that this approach needs visual markers in the environment, the user and the robot need to be in the same environment for the mobile version and the AR overlay helps the user and the robot interact better.\\n\\n\\n#### Bio-signal-based\\n- https://link.springer.com/article/10.1007/s10514-020-09916-x\\n    - earlier work used only EEG: http://groups.csail.mit.edu/drl/wiki/images/e/ec/Correcting_Robot_Mistakes_in_Real_Time_Using_EEG_Signals.pdf\\n    - Uses EMG(muscle) + EEG(brain) to give swift feedback to robot\\n    - EMG is used to detect the users intention, EEG is used to detect potential errors the robot or the human makes\\n    - summary:\\n    In the paper \\\\cite the authors used a hybrid of electromyography (EMG) and electroencephalography (EEG) to control a arm with a tool on it. The robot was supposed to hit one of three holes in the wall in front of it with the electric screwdriver in their hand. The user is equipped with electrodes on their head and surface bar electrodes are applied to their forearms. The signals of those devices are processed separately and then used to determine the action of the robot arm.\\n    The user observes the robot and its environment directly and tries to move the tool in the robots hand via muscle movements. When the robot or the user themself make a mistake, the users brain reacts a certain way, often unconsciously, which can be detected by the EEG processor. Those signals are then used to stop and then correct the robot.\\n    The system was evaluated on 7 participants. The users were untrained, to reduce the hurdle for new users. The correct target was hit in roughly 70% of the trials, when the robot randomly chose. With the help of the correction through the participant, the success rate jumped to 97%.\\n    The authors concluded, that the reliability needs to be improved to be able to deploy the system in safety critical situations. Specifically, the neural network that classified the EEG signal into mistake or no-mistake, had only a 54% accuracy. They also highlight that more users would be needed to make the system more robust towards inter-person variations. However, the system shows potential for an effective supervision system.\\n\\n- https://www.jmir.org/2019/10/e16194/\\n    - neuralink whitepaper\\n    - uses brain signals to control a robot\\n    - might be interesting, but not used on humans yet\\n    - don\'t know if it \\"counts\\" as an example\\n    - mainly describes a way to get information out of the human brain, not however how to interpret it or control a robot.\\n    - but really important\\n\\n- https://static.aminer.org/pdf/PDF/000/329/658/emg_based_human_machine_interface_system.pdf\\n    - example of using EMG to control a robot\\n    - really old paper\\n\\n\\n## Comparison\\n\\nAR is the cheapest of the three, as no special hardware is needed most of the time. VR however has huge upside of remote operation, by emerging the user in the distant environment. Additionally VR can be more intuitive because the user can be \\"in the skin\\" of the robot. Bio-signal-based solutions are in the early stages but offer huge potential for swift intuitive interaction with robots.\\n\\n|                  | Example use cases | Example devices | ease of use | unique functions | cost | future potential |\\n| ---------------- | ----------------- | --------------- | ----------- |------------------| ---- | ---------------- |\\n| VR               |control robot motion over internet by moving controllers and observing results|Oculus rift, Meta quest pro, smartphone| special equipment necessary (headset and controllers), often uncomfortable for long periods of time, either battery (limited work time) or cables (limited motion range)| teleoperation, see whole environment of the robot from somewhere else; ego perspective and feel of robot (step into skin of robot, more hands on), but strong stable internet connection necessary|expensive special equipment, getting cheaper when consumer grade equipment can be used|might become important to remotely help out \\"almost fully\\" autonomous systems in difficult situations; need better form factors|\\n| AR               |display important robot information about the robot(range of motion, wear and tear, pre-rendering of action)|google glasses, tablet, smartphone|really simple|no special equipment required|pretty low, no special equipment|integration into normal glasses, or contact lenses|\\n| Bio-signal-based |signal if robot did right or wrong action directly with ones mind, control of prosthesis via muscle signals(EMG)|implants (Neuralink), EEG, EMG, etc.|some special equipment needed, sometimes easy to use (wrist bands), sometimes permanent augment (implant)|if implemented well, can read the humans mind and make robot smooth extension of human|ranges from cheap(wrist bands) to expensive(implants)|huge potential to merge with robots and full control of a robot with a humans thoughts|\\n\\n### Use cases\\n- VR\\n    - teleoperation\\n    - swarm operation\\n    - full birds eye view or different perspective\\n- AR\\n    - display important information about the environment and the robot\\n\\n- Bio-signal-based\\n    - control of robot\\n    - possibly more complex, and faster controls possible\\n\\n- Comparison\\nVR has the special property that it can transport the user into a completely different environment to control a robot through teleoperation. Additionally one can view the environment from any perspective, for example a birds eye view, as in \\\\ref. This can help to gain an overview over the environment and thus control swarms or other robots.\\nAR and bio-signal-based technologies have direct visual contact from the user or through the camera of a handheld device, like a tablet \\\\ref, most of the time.\\nHowever, AR can enhance the real environment with important information about the workspace and the robot. This can help the user to perform the tasks faster and saver. It is to be noted that technically VR can do the same, by recording the environment with its front camera and displaying the information in the headset, but the user might have a lower field of view compared to AR glasses or a tablet.\\nBio-signal-based technologies can be used to control the robot directly with ones mind (EEG) or muscles (EMG), like in \\\\ref. The applications are still limited to simple controls of robot arms or the detection of mistakes with the human mind.\\nThe main difference to AR and VR is the fact that the reactions can be faster as the thinking about the mistake can be detected unconsciously by the system. The main issue is that the reliability is still low and thus not save to use with big and powerful robots.\\n\\n### Devices\\n- VR\\n    - Meta quest 2\\n    - smartphone\\n\\n- AR\\n    - google glasses\\n    - tablet\\n    - smartphone\\n\\n- Bio-signal-based\\n    - EEG\\n    - EMG\\n    - implants (Neuralink)\\n\\n- Comparison\\nVR devices are mostly headsets to display the environment with controllers to control the robot and the position of the user. For headsets, the Meta Quest 2/Pro or the Valve Index can be used. For the controllers, Razer Hydra hand trackers or the default VR controllers that come with the headsets are available. The user can also use a smartphone as a headset, but the field of view is limited, the performance might not be enough and the resolution is not as good as with a dedicated headset.\\nFor AR, dedicated glasses are still early in the development. However handheld devices like tablets or smartphones can be used as well, as in \\\\ref.\\nBio-signal-based devices can be wrist bands, that measure muscle contraction, electrodes on the scalp to measure signals from the brain or various other specialized technology. One main difference is that VR and AR devices are bought on the consumer market, which can help with cost and development, whereas bio-signal-based devices aren\'t often used in everyday live.\\n\\n### Ease of use\\n- VR\\n    - special equipment necessary (headset and controllers), often uncomfortable for long periods of time, either battery (limited work time) or cables (limited motion range)\\n    - intuitive, ego perspective\\n- AR\\n    - really simple\\n    - need to control by touchscreen, which is not as intuitive as VR\\n\\n- Bio-signal-based\\n    - some special equipment needed, sometimes easy to use (wrist bands), sometimes permanent augment (implant)\\n\\n- comparison\\n\\n### Cost\\n\\nTable:\\n\\n| technology | device | cost | link |\\n| ---------- | ------ | ---- | ---- |\\n| VR         | Meta Quest 2 | 450$ | https://www.meta.com/de/en/quest/products/quest-2/ |\\n| VR         | Valve Index | 1079$ | https://store.steampowered.com/valveindex |\\n| AR         | I-pad | 449$ | https://www.apple.com/shop/buy-ipad/ipad |\\n| AR         | Galaxy Tab S8 | 200$ | https://www.samsung.com/us/tablets/galaxy-tab-s8/buy/ |\\n| AR         | Google Glasses | 999$ | https://www.theverge.com/2019/5/20/18632689/google-glass-enterprise-edition-2-augmented-reality-headset-pricing |\\n| Bio-signal-based | EEG electrode hat | 1500$ | https://shop.openbci.com/collections/frontpage |\\n\\n- comparison\\nTo compare the cost of the different technologies, The prices of the different devices were looked up and summarized in \\\\ref. Note that this is only a fraction of possible devices.\\nThe low end Meta Quest 2 in the same price range as the high end I-Pad. But when comparing the more powerful Valve Index, to a more budget tablet, like the Galaxy Tab S8, VR devices are considerably more expensive than a basic AR device. Additionally for most VR headsets, an additional high end PC is necessary to process the visuals.\\nAnother alternative for AR are the Google Glasses, which come at a higher price, similar to the VR headsets.\\nBio-signal-based devices, specifically EEG, are starting at the price of a VR headset. They might however get cheaper if those devices get produced in higher numbers. The prices can get way higher as well, if implants through operations are used.\\nSo in general, AR is the cheapest option, as one can simply use a smartphone or a tablet. VR requires some special technology in form of a headset and probably a high end PC. Finally, the bio-signal-based devices come out as most expensive, as they are still early in development.\\n\\n\\n### Problems\\nThe main ways VR and AR can improve from today are general hardware improvements like better batteries, \\n### Future potential\\n- VR\\n    - might become important to remotely help out \\"almost fully\\" autonomous systems in difficult situations\\n    - need better form factors and better hardware:\\n        - batteries\\n        - more comfortable\\n- AR\\n    - integration into normal glasses, or contact lenses\\n    - more powerful hardware, or remote processing\\n\\n- Bio-signal-based\\n    - huge potential to merge with robots and full control of a robot with a humans thoughts\\n    - more consumer based hardware\\n    - improved reliability\\n\\n- Comparison:\\nVR might be used at some point to have the human help out almost fully autonomous systems by stepping in the perspective of the robot. Or it can be used to fully control robots remotely and remove the need for humans to work in dangerous environments.\\nAR could have a huge jump in usability if it were to be integrated into everyday glasses or even contact lenses. This could enable people without training to use them. If robots are more common in everyday life this might increase the trust in the robots by displaying certain information about the robots future actions in the environment.\\nBio-signal-based technologies could be used to completely and reliably control robots with human thoughts, which would be a huge step in the field of human-robot interaction. If this technology is achieved, most other control devices might be obsolete.\\nSo the biggest potential certainly lies within EEG technologies, as they can enable a direct link between human and robot. However the other two technologies might also play a crucial role in some more niche cases.\\n\\n\\n## Conclusion\\n- Summarize the key points and findings of the paper:\\nIn summary, it is difficult to compare the three technologies, because they each have their different use cases, as seen in \\\\ref. Additionally, they are never tested against each other, with regard to user feedback.\\nWhen comparing the use cases, VR shows a clear advantage in teleoperation, AR in merging digital information into the real world environment and bio-signal-based technology can use quick reactions directly from the human brain to mitigate mistakes.\\n\\n- Highlight the main contributions of the paper and its impact on the field of HRI interfaces:\\nThis paper compares some examples of the three technologies and their use cases. It also extrapolates those comparisons to the whole categories. Hopefully it can give some ideas on the future research directions of the field. Additionally, this is an encouragement to further investigate how to better compare the three technologies to then be able to better predict what technology is worth more efforts. To conclude this report, some recommendations for future research are the following.\\n\\n- Discuss future directions for research in HRI interfaces, including VR, AR, and bio-signal-based:\\n\\nThe final achievement would be to have a direct link between human and robot in both directions. Until then, all three technologies will need to be improved gradually.\\nFor VR, the ability to wear the headset for a long time and training programs should be the focus.\\nAR might be more useful, if the technology gets integrated better into glasses to not need an extra tablet while working with a robot in the workspace. \\nBio-signal-based technologies first need to improve their reliability before they can be used in real-world applications. A next step would be to improve the designs behind the devices, so they can be used more for consumer products and accelerate the development.\\n\\n## todo\\n- add picture maybe\\n- add VR/AR review"},{"id":"/logic","metadata":{"permalink":"/blog/logic","source":"@site/blog/logic.md","title":"Logic","description":"Some wiki stuff:","date":"2023-09-23T15:55:21.000Z","formattedDate":"September 23, 2023","tags":[],"readingTime":0.715,"hasTruncateMarker":false,"authors":[],"frontMatter":{"title":"Logic","layout":"base"},"prevItem":{"title":"Human Robot Interaction","permalink":"/blog/hri"},"nextItem":{"title":"Machine Learning","permalink":"/blog/machine_learning"}},"content":"## Some wiki stuff:\\n\\n- [Argument map](https://en.wikipedia.org/wiki/Argument_map)\\n- [Logical form](https://en.wikipedia.org/wiki/Logical_form)\\n\\n## Idea\\n\\nIt would be cool to have a somewhat standarised form of arguments or moral systems. This could be in form of an Argument map in a huge tree and implemented on a website or in a program.\\n\\nSo one could create ones own tree of axioms, premisses and conclusions. Those could be shared and argued about. The program could help identifiy contentions between two peoples moral systems so one can instantly focus on the disagreements.\\n\\nThe main issue is the uglieness of human input. Even with a some standard blocks like axioms and other logical forms humans still input their claims differently. So one would need some machine learning to interpret and compare arguments. With the advancements of language models like [GTP-3](https://en.wikipedia.org/wiki/GPT-3) one may be able to achieve some decent results."},{"id":"/machine_learning","metadata":{"permalink":"/blog/machine_learning","source":"@site/blog/machine_learning.md","title":"Machine Learning","description":"Preparation","date":"2023-09-23T15:55:21.000Z","formattedDate":"September 23, 2023","tags":[],"readingTime":1.48,"hasTruncateMarker":false,"authors":[],"frontMatter":{"title":"Machine Learning","layout":"base"},"prevItem":{"title":"Logic","permalink":"/blog/logic"},"nextItem":{"title":"Neural network","permalink":"/blog/neural_network"}},"content":"## Preparation\\nGoing Through [CS50](https://cs50.harvard.edu/college/2022/spring/notes/0/) for refresh of some basics ([Notes](cs50)).\\n\\n## Sources\\n[Roadmap/Plan](https://machinelearningmastery.com/start-here/)  \\n[Motivation/Karpathy is a cool dude](http://karpathy.github.io/2022/03/14/lecun1989/)\\n\\n## Problem description\\n\\n> Find a model or procedure that makes best use of historical data comprised of inputs and outputs in order to skillfully predict outputs given new and unseen inputs in the future. [[1]](https://machinelearningmastery.com/think-machine-learning/#:~:text=Find%20a%20model%20or%20procedure%20that%20makes%20best%20use%20of%20historical%20data%20comprised%20of%20inputs%20and%20outputs%20in%20order%20to%20skillfully%20predict%20outputs%20given%20new%20and%20unseen%20inputs%20in%20the%20future.)\\n\\n## Problem solution\\n\\n> A model or procedure that automatically creates the most likely approximation of the unknown underlying relationship between inputs and associated outputs in historical data. [[1]](https://machinelearningmastery.com/think-machine-learning/#:~:text=as%20the%20following%3A-,A%20model%20or%20procedure%20that%20automatically%20creates%20the%20most%20likely%20approximation%20of%20the%20unknown%20underlying%20relationship%20between%20inputs%20and%20associated%20outputs%20in%20historical%20data.,-Again%2C%20this%20is)\\n\\n## How to get there\\n\\n### Define the problem\\n\\n- Describe problem informally and formally and list assumptions and similar problems\\n- List motivations for solving the problem, the benefits a solution provides and how the solution will be used.\\n- Describe how the problem could be solved manually.\\n\\n### Prepare Data\\n\\n- Consider what data is available, what data is missing and what data can be removed.\\n- Organize your selected data by formatting, cleaning and sampling from it.\\n- Transform preprocessed data into features ready for machine learning.\\n\\n### Spot check algorithms\\n\\n- create small experiment with different transformations of the dataset and different standard algorithms\\n- run every pair a bunch of times and compare mean and variance\\n- helps flushing out the problem structure and getting the algorithms on which to focus in the next steps\\n\\n### Improving Results\\n\\n- Search through parameter space to find best performing models\\n- Ensemble: combine results of multiple models\\n\\n### Present Results\\n\\n- Define the context of the problem and the motivation\\n- Describe Problem as a question that got answered\\n- Concisely describe the solution as an answer to the question\\n- Specify limitations of the model, what questions it can\'t answer and with what probability it can answer questions"},{"id":"/neural_network","metadata":{"permalink":"/blog/neural_network","source":"@site/blog/neural_network.md","title":"Neural network","description":"Intuitive understanding","date":"2023-09-23T15:55:21.000Z","formattedDate":"September 23, 2023","tags":[],"readingTime":0.99,"hasTruncateMarker":false,"authors":[],"frontMatter":{"title":"Neural network","layout":"base"},"prevItem":{"title":"Machine Learning","permalink":"/blog/machine_learning"},"nextItem":{"title":"notes","permalink":"/blog/notes"}},"content":"## Intuitive understanding\\n\\nA neural network is pretty much just a function that maps a bunch of inputs to a bunch of outputs. First that function does bad at mapping. By showing a lot of input/output pairs the parameters in the function get adjusted to improve the mapping.\\n\\nSo there are three big parts of a neural network. The architecture of the network, the optimization of the parameters and the amount and quality of the data.\\n\\n## Architecture\\n\\n- How many layers?\\n- What type of layers?\\n- What activation functions?\\n- Input and output dimensions?\\n\\n## Optimization\\n\\n- What does the loss function look like?\\n- Gradient descent?\\n- What optimizer?\\n- When and how fast to change the parameters?\\n- When to stop training?\\n- Is there overfitting?\\n\\n## Data\\n\\n- How much data is there?\\n- Is Data argumentation necessary and/or useful?\\n- Can there be too much data?\\n- Is there bias in data?\\n\\n# Practical Stuff\\n\\n## Perceptron\\n\\nThe Perceptron is the simplest neural network possible.\\n\\n## Implement small deep learning library from scratch (with numpy)\\n\\nAt some point!! To help with a deeper understanding of backpropagation and the inner workings in general."},{"id":"/notes","metadata":{"permalink":"/blog/notes","source":"@site/blog/notes.md","title":"notes","description":"Destiny notes","date":"2023-09-23T15:55:21.000Z","formattedDate":"September 23, 2023","tags":[],"readingTime":0.895,"hasTruncateMarker":false,"authors":[],"frontMatter":{},"prevItem":{"title":"Neural network","permalink":"/blog/neural_network"},"nextItem":{"title":"PyTorch","permalink":"/blog/pytorch"}},"content":"\x3c!-- --- --\x3e\\n\x3c!-- title: Notes --\x3e\\n\x3c!-- layout: base --\x3e\\n\x3c!-- --- --\x3e\\n\\n\\n## Destiny notes\\n\\n- Website to organize Destiny\'s arguments in a nice format with logic structure\\n- link to segments/proofs\\n\\n### overarching points\\n\\n- All the points are supposed to be examples of the application of a system\\n- This system is used to generate good outcomes in your live\\n- So don\'t try to copy the outcome of the points, as they are based on Destiny\'s subjective values and environment\\n- Instead try to understand the system and apply it to your own life\\n\\n###\\n- Act as a sounding board when talking with emotional friend\\n- if you have the choice between burning someone to the ground or leaving it neutral, leave it neutral\\n- be really careful when comparing people, especially when both are friends\\n    - e.g. Comparing body parts\\n\\n\\n## AI vs human\\n\\n- Website with question\\n- need to select real answer, from real and AI generated answer\\n- AI generated answer is instructed to sound like human (gpt3 api)"},{"id":"/pytorch","metadata":{"permalink":"/blog/pytorch","source":"@site/blog/pytorch.md","title":"PyTorch","description":"Data Loading","date":"2023-09-23T15:55:21.000Z","formattedDate":"September 23, 2023","tags":[],"readingTime":0.12,"hasTruncateMarker":false,"authors":[],"frontMatter":{"title":"PyTorch","layout":"base"},"prevItem":{"title":"notes","permalink":"/blog/notes"},"nextItem":{"title":"Search","permalink":"/blog/search"}},"content":"## Data Loading\\n\\nFor a custom dataset one needs to implement the Dataset class even if its the most basic dataset.\\n\\n## Derivatives\\n\\n[](https://machinelearningmastery.com/calculating-derivatives-in-pytorch/)"},{"id":"/search","metadata":{"permalink":"/blog/search","source":"@site/blog/search.md","title":"Search","description":"Implementation of different search algorithms in python.","date":"2023-09-23T15:55:21.000Z","formattedDate":"September 23, 2023","tags":[],"readingTime":1.245,"hasTruncateMarker":false,"authors":[],"frontMatter":{"title":"Search","layout":"base"},"prevItem":{"title":"PyTorch","permalink":"/blog/pytorch"},"nextItem":{"title":"Sort","permalink":"/blog/sort"}},"content":"Implementation of different search algorithms in python.\\n\\nSample Array:\\n```python\\nx = [3,1,4,5,9,6,2]\\n```\\n\\nGoal:\\n\\nSearch 1 specific number. If not in array, return `-1`. If in array return the index of the number.\\n\\n## Linear Search\\n\\nJust look through every entry from left to right and check if the entry is equal to the target.\\n\\n```python\\ndef linear(input, target):\\n    for idx, entry in enumerate(input):\\n        if entry == target:\\n            return idx\\n    return -1\\n```\\n\\nComplexity:  \\n\\\\\\\\(O(n)\\\\\\\\)  \\n\\\\\\\\(\\\\Omega(1)\\\\\\\\)\\n\\n## Binary Search\\n\\nOnly works with a sorted list!  \\nLook at the middle of the list first and check if that entry is the target. If it isn\'t the target, compare that number with the target. If the target is higher, repeat from the first step with the right half of the list, otherwise with the left half.\\n\\n```python\\ndef binary(input, target, idx = None):\\n    \\n    length = len(input)\\n\\n    if length == 0:\\n        return -1\\n\\n    middle = length//2\\n\\n    if idx == None:\\n        idx = middle\\n\\n    if input[middle]==target:\\n        return idx\\n\\n    if input[middle]>target:\\n        return binary(input[:middle], target, idx-((middle//2)+1))\\n    else:\\n        return binary(input[middle+1:], target, idx+((middle//2)+1))\\n```\\n\\nComplexity:  \\n\\\\\\\\(O(\\\\log n)\\\\\\\\)  \\n\\\\\\\\(\\\\Omega(1)\\\\\\\\)\\n\\n## Sorting\\n\\n**Now the question is:**  \\nIs it better to just do linear search or sort the array and then do binary search. For one search linear search would make more sense. However in practice the same arrays often get searched multiple times. So it is better to sort them once and then do binary search multiple times on the sorted array to save time.   \\n[Some Sort Algorithms.](sort)"},{"id":"/sort","metadata":{"permalink":"/blog/sort","source":"@site/blog/sort.md","title":"Sort","description":"Implementation of different search algorithms in python.","date":"2023-09-23T15:55:21.000Z","formattedDate":"September 23, 2023","tags":[],"readingTime":1.435,"hasTruncateMarker":false,"authors":[],"frontMatter":{"title":"Sort","layout":"base"},"prevItem":{"title":"Search","permalink":"/blog/search"},"nextItem":{"title":"Tidy data","permalink":"/blog/tidy_data"}},"content":"Implementation of different search algorithms in python.\\n\\nSample Array:\\n```python\\nx = [3,1,4,5,9,6,2]\\n```\\n\\nGoal:\\n\\nSort array from lowest to highest entry and return it.\\n\\n## Selection sort\\n\\nGo through whole list and find the lowest number. Swap that number with the first number in the list. Start with one position to the right and repeat.\\n\\n```python\\ndef selection(input):\\n\\n    for i in range(len(input)):\\n\\n        min_idx = i\\n        for j in range(i,len(input)):\\n            if input[j] < input[min_idx]:\\n                min_idx = j\\n        \\n        input[i], input[min_idx] = input[min_idx], input[i]\\n\\n    return input\\n```\\nComplexity:  \\n\\\\\\\\(O(n^2)\\\\\\\\)  \\n\\\\\\\\(\\\\Omega(n^2)\\\\\\\\)\\n\\n## Bubble sort\\n\\nGo through list and check if number is higher than the following number. If yes, swap the two numbers. If no, go to the next number. Repeat from the first step, but end one further position to the left.\\n\\n```python\\ndef bubble(input):\\n\\n    for i in range(len(input)):\\n        for j in range(len(input)-i-1):\\n            if input[j] > input[j+1]:\\n                input[j], input[j+1] = input[j+1], input[j]\\n\\n\\n    return input\\n```\\nComplexity:  \\n\\\\\\\\(O(n^2)\\\\\\\\)  \\n\\\\\\\\(\\\\Omega(n)\\\\\\\\)\\n\\n## Merge sort\\n\\nDivide list in middle and recursively repeat for left and right. When a list is only 1 number return it. When two of these lists got returned, they are sorted. Then they are combined again, by looking at the first entry in each list and appending the lower number to the result. Repeat until right and left are \\"empty\\".\\n\\n```python\\ndef merge(input):\\n\\n    if len(input)==1:\\n        return input\\n\\n    middle = len(input)//2\\n\\n    left, right = input[:middle], input[middle:]\\n\\n    left = merge(left)\\n    right = merge(right)\\n\\n    result=[]\\n\\n    i = j = 0\\n    while i < len(left) and j < len(right):\\n        if left[i]<right[j]:\\n            result.append(left[i])\\n            i+=1\\n        else:\\n            result.append(right[j])\\n            j+=1\\n    \\n    if i < len(left):\\n        result += left[i:]\\n\\n    if j < len(right):\\n        result += right[j:]\\n\\n    return result\\n```\\nComplexity:  \\n\\\\\\\\(O(n \\\\log n)\\\\\\\\)  \\n\\\\\\\\(\\\\Omega(n \\\\log n)\\\\\\\\)\\n\\n## Visualization\\n\\n[Here.](https://www.cs.usfca.edu/~galles/visualization/ComparisonSort.html)"},{"id":"/tidy_data","metadata":{"permalink":"/blog/tidy_data","source":"@site/blog/tidy_data.md","title":"Tidy data","description":"Mostly a summary of the paper tidy data.","date":"2023-09-23T15:55:21.000Z","formattedDate":"September 23, 2023","tags":[],"readingTime":0.94,"hasTruncateMarker":false,"authors":[],"frontMatter":{"title":"Tidy data","layout":"base"},"prevItem":{"title":"Sort","permalink":"/blog/sort"},"nextItem":{"title":"Knowing the unknown","permalink":"/blog/unknown"}},"content":"Mostly a summary of the paper [tidy data](https://vita.had.co.nz/papers/tidy-data.pdf).\\n\\nExample of badly formatted data:\\n\\n||treatmenta|treatmentb|\\n|---|---|---|\\n|John Smith|-|2|\\n|Jane Doe|16|11|\\n|Mary Johnson|3|1|\\n\\nBetter formatted version of that data:\\n\\n|name|trt|result|\\n|---|---|---|\\n|Jane Doe|a|16|\\n|Jane Doe|b|11|\\n|John Smith|a|-|\\n|John Smith|b|2|\\n|Mary Johnson|a|3|\\n|Mary Johnson|b|1|\\n\\nImportant guidelines:\\n- Rows: observations\\n- Columns: variables\\n- Values: variable values at specific observations\\n\\nOrder:\\n- variables: fixed (descriptions of the experiment) first, then measured variables, always the ones related to each other next to each other\\n- observations: order by first variable, then break ties with the following variables\\n\\nThis leads to a standard, which is important as programs knows how their input is structured. So they can take the data, transform it and return tidy data again.\\n\\n# From messy to tidy\\n\\nTo get a dataset from messy to tidy one can employ three operations:\\n\\n## Melting\\nTurns multiple columns that are variables into a column with the names of the specific columns and a column with the value.\\n\\n### Messy:\\n\\n|row|a|b|c|\\n|---|---|---|---|\\n|A|1|4|7|\\n|B|2|5|7|\\n|C|3|6|9|\\n\\n### Molten:\\n\\n|row|column|value|\\n|---|---|---|\\n|A|a|1|\\n|A|b|4|\\n|A|c|7|\\n|B|a|2|\\n|B|b|5|\\n|B|c|8|\\n|C|a|3|\\n|C|b|6|\\n|C|c|9|\\n\\n## String splitting\\n## Casting"},{"id":"/unknown","metadata":{"permalink":"/blog/unknown","source":"@site/blog/unknown.md","title":"Knowing the unknown","description":"Why are people often times so bad when they don\'t have all information. And cant deal with probabilities.","date":"2023-09-23T15:55:21.000Z","formattedDate":"September 23, 2023","tags":[],"readingTime":0.09,"hasTruncateMarker":false,"authors":[],"frontMatter":{"layout":"base","title":"Knowing the unknown"},"prevItem":{"title":"Tidy data","permalink":"/blog/tidy_data"}},"content":"Why are people often times so bad when they don\'t have all information. And cant deal with probabilities."}]}')}}]);